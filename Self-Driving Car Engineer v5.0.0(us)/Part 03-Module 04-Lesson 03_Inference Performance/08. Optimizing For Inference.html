<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Optimizing For Inference
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Inference Performance
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Intro.html">
       01. Intro
      </a>
     </li>
     <li class="">
      <a href="02. Why Bother With Performance.html">
       02. Why Bother With Performance
      </a>
     </li>
     <li class="">
      <a href="03. Semantic Segmentation Revisited.html">
       03. Semantic Segmentation Revisited
      </a>
     </li>
     <li class="">
      <a href="04. Interlude Using The AMI.html">
       04. Interlude: Using The AMI
      </a>
     </li>
     <li class="">
      <a href="05. Freezing Graphs.html">
       05. Freezing Graphs
      </a>
     </li>
     <li class="">
      <a href="06. Graph Transforms.html">
       06. Graph Transforms
      </a>
     </li>
     <li class="">
      <a href="07. Fusion.html">
       07. Fusion
      </a>
     </li>
     <li class="">
      <a href="08. Optimizing For Inference.html">
       08. Optimizing For Inference
      </a>
     </li>
     <li class="">
      <a href="09. Reducing Precision.html">
       09. Reducing Precision
      </a>
     </li>
     <li class="">
      <a href="10. Quantization Quiz.html">
       10. Quantization Quiz
      </a>
     </li>
     <li class="">
      <a href="11. Quantization Conversion.html">
       11. Quantization Conversion
      </a>
     </li>
     <li class="">
      <a href="12. 8-bit Calculations.html">
       12. 8-bit Calculations
      </a>
     </li>
     <li class="">
      <a href="13. Compilation.html">
       13. Compilation
      </a>
     </li>
     <li class="">
      <a href="14. AOT &amp; JIT.html">
       14. AOT &amp; JIT
      </a>
     </li>
     <li class="">
      <a href="15. Reusing The Graph.html">
       15. Reusing The Graph
      </a>
     </li>
     <li class="">
      <a href="16. Outro.html">
       16. Outro
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          08. Optimizing For Inference
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Once the graph is frozen there are a variety of transformations that can be performed; dependent on what we wish to achieve. TensorFlow has packaged up some inference optimizations in a tool aptly called
          <code>
           optimize_for_inference
          </code>
          .
         </p>
         <p>
          <code>
           optimize_for_inference
          </code>
          does the following:
         </p>
         <ul>
          <li>
           Removes training-specific and debug-specific nodes
          </li>
          <li>
           Fuses common operations
          </li>
          <li>
           Removes entire sections of the graph that are never reached
          </li>
         </ul>
         <p>
          Here’s how it can be used:
         </p>
         <pre><code class="bash language-bash">~/tensorflow/bazel-bin/tensorflow/python/tools/optimize_for_inference \
--input=frozen_graph.pb \
--output=optimized_graph.pb \
--frozen_graph=True \
--input_names=image_input \
--output_names=Softmax</code></pre>
         <p>
          We'll use the graph we just froze as the input graph,
          <code>
           input
          </code>
          .
          <code>
           output
          </code>
          is the name of the output graph; we’ll be creative and call it
          <code>
           optimized_graph.pb
          </code>
          .
         </p>
         <p>
          The
          <code>
           optimize_for_inference
          </code>
          tool works for both frozen and unfrozen graphs, so we have to specify whether the graph is already frozen or not with
          <code>
           frozen_graph
          </code>
          .
         </p>
         <p>
          <code>
           input_names
          </code>
          and
          <code>
           output_names
          </code>
          are the names of the input and output nodes respectively. As the option names suggest, there can be more than one input or output node, separated by commas.
         </p>
         <p>
          Let’s take a look at the effect this has on the number of operations.
         </p>
         <pre><code class="python language-python">from graph_utils import load_graph

sess, optimized_ops = load_graph('optimized_graph.pb')
print(len(optimized_ops)) # 200</code></pre>
         <p>
          Cool, Now there are only 200 operations in the graph!
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="09. Reducing Precision.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('08. Optimizing For Inference')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
