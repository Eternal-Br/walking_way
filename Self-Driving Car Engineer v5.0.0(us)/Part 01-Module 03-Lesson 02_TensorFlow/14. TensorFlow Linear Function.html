<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   TensorFlow Linear Function
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      TensorFlow
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Deep Learning Frameworks.html">
       01. Deep Learning Frameworks
      </a>
     </li>
     <li class="">
      <a href="02. Introduction to Deep Neural Networks.html">
       02. Introduction to Deep Neural Networks
      </a>
     </li>
     <li class="">
      <a href="03. What is Deep Learning.html">
       03. What is Deep Learning?
      </a>
     </li>
     <li class="">
      <a href="04. Solving Problems - Big and Small.html">
       04. Solving Problems - Big and Small
      </a>
     </li>
     <li class="">
      <a href="05. Let's Get Started!.html">
       05. Let's Get Started!
      </a>
     </li>
     <li class="">
      <a href="06. Installing TensorFlow.html">
       06. Installing TensorFlow
      </a>
     </li>
     <li class="">
      <a href="07. Hello, Tensor World!.html">
       07. Hello, Tensor World!
      </a>
     </li>
     <li class="">
      <a href="08. Quiz Tensorflow Input.html">
       08. Quiz: Tensorflow Input
      </a>
     </li>
     <li class="">
      <a href="09. Quiz Tensorflow Math.html">
       09. Quiz: Tensorflow Math
      </a>
     </li>
     <li class="">
      <a href="10. Transition to Classification.html">
       10. Transition to Classification
      </a>
     </li>
     <li class="">
      <a href="11. Supervised Classification.html">
       11. Supervised Classification
      </a>
     </li>
     <li class="">
      <a href="12. Let's make a deal.html">
       12. Let's make a deal
      </a>
     </li>
     <li class="">
      <a href="13. Training Your Logistic Classifier.html">
       13. Training Your Logistic Classifier
      </a>
     </li>
     <li class="">
      <a href="14. TensorFlow Linear Function.html">
       14. TensorFlow Linear Function
      </a>
     </li>
     <li class="">
      <a href="15. Quiz Linear Function.html">
       15. Quiz: Linear Function
      </a>
     </li>
     <li class="">
      <a href="16. Linear Update.html">
       16. Linear Update
      </a>
     </li>
     <li class="">
      <a href="17. Quiz Softmax.html">
       17. Quiz: Softmax
      </a>
     </li>
     <li class="">
      <a href="18. Quiz TensorFlow Softmax Workspaces.html">
       18. Quiz: TensorFlow Softmax Workspaces
      </a>
     </li>
     <li class="">
      <a href="19. One-Hot Encoding.html">
       19. One-Hot Encoding
      </a>
     </li>
     <li class="">
      <a href="20. Quiz One-Hot Encoding.html">
       20. Quiz: One-Hot Encoding
      </a>
     </li>
     <li class="">
      <a href="21. Cross Entropy.html">
       21. Cross Entropy
      </a>
     </li>
     <li class="">
      <a href="22. Minimizing Cross Entropy.html">
       22. Minimizing Cross Entropy
      </a>
     </li>
     <li class="">
      <a href="23. Practical Aspects of Learning.html">
       23. Practical Aspects of Learning
      </a>
     </li>
     <li class="">
      <a href="24. Quiz Numerical Stability.html">
       24. Quiz: Numerical Stability
      </a>
     </li>
     <li class="">
      <a href="25. Normalized Inputs and Initial Weights.html">
       25. Normalized Inputs and Initial Weights
      </a>
     </li>
     <li class="">
      <a href="26. Measuring Performance.html">
       26. Measuring Performance
      </a>
     </li>
     <li class="">
      <a href="27. Transition Overfitting - Dataset Size.html">
       27. Transition: Overfitting -&gt; Dataset Size
      </a>
     </li>
     <li class="">
      <a href="28. Validation and Test Set Size.html">
       28. Validation and Test Set Size
      </a>
     </li>
     <li class="">
      <a href="29. Validation Set Size.html">
       29. Validation Set Size
      </a>
     </li>
     <li class="">
      <a href="30. Validation Test Set Size Continued.html">
       30. Validation Test Set Size Continued
      </a>
     </li>
     <li class="">
      <a href="31. Optimizing a Logistic Classifier.html">
       31. Optimizing a Logistic Classifier
      </a>
     </li>
     <li class="">
      <a href="32. Stochastic Gradient Descent.html">
       32. Stochastic Gradient Descent
      </a>
     </li>
     <li class="">
      <a href="33. Momentum and Learning Rate Decay.html">
       33. Momentum and Learning Rate Decay
      </a>
     </li>
     <li class="">
      <a href="34. Parameter Hyperspace! .html">
       34. Parameter Hyperspace!
      </a>
     </li>
     <li class="">
      <a href="35. Mini-batch.html">
       35. Mini-batch
      </a>
     </li>
     <li class="">
      <a href="36. Quiz 2 Mini-batch.html">
       36. Quiz 2: Mini-batch
      </a>
     </li>
     <li class="">
      <a href="37. Epochs.html">
       37. Epochs
      </a>
     </li>
     <li class="">
      <a href="38. Intro TensorFlow Neural Network .html">
       38. Intro TensorFlow Neural Network
      </a>
     </li>
     <li class="">
      <a href="39. Lab Neural Network Workspaces.html">
       39. Lab: Neural Network Workspaces
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          14. TensorFlow Linear Function
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="tensorflow-linear-function">
          TensorFlow Linear Function
         </h1>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Let’s derive the function
          <code>
           y = Wx + b
          </code>
          .  We want to translate our input,
          <code>
           x
          </code>
          , to labels,
          <code>
           y
          </code>
          .
         </p>
         <p>
          For example, imagine we want to classify images as digits.
         </p>
         <p>
          <code>
           x
          </code>
          would be our list of pixel values, and
          <code>
           y
          </code>
          would be the logits, one for each digit. Let's take a look at
          <code>
           y = Wx
          </code>
          , where the weights,
          <code>
           W
          </code>
          , determine the influence of
          <code>
           x
          </code>
          at predicting each
          <code>
           y
          </code>
          .
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/wx-1.jpg"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          <code>
           y = Wx
          </code>
          allows us to segment the data into their respective labels using a line.
         </p>
         <p>
          However, this line has to pass through the origin, because whenever
          <code>
           x
          </code>
          equals 0, then
          <code>
           y
          </code>
          is also going to equal 0.
         </p>
         <p>
          We want the ability to shift the line away from the origin to fit more complex data.  The simplest solution is to add a number to the function, which we call “bias”.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Function y = Wx + b" class="img img-fluid" src="img/wx-b.jpg"/>
          <figcaption class="figure-caption">
           <p>
            Function y = Wx + b
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Our new function becomes
          <code>
           Wx + b
          </code>
          , allowing us to create predictions on linearly separable data.  Let’s use a concrete example and calculate the logits.
         </p>
         <h2 id="matrix-multiplication-quiz">
          Matrix Multiplication Quiz
         </h2>
         <p>
          Calculate the logits
          <code>
           a
          </code>
          and
          <code>
           b
          </code>
          for the following formula.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="y = Wx + b" class="img img-fluid" src="img/codecogseqn-13.gif"/>
          <figcaption class="figure-caption">
           <p>
            y = Wx + b
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <form>
          <fieldset>
           <legend>
            <p>
             What is a?
            </p>
           </legend>
          </fieldset>
          <div>
           <input id="a1525817423666" name="626423" type="radio" value="a1525817423666"/>
           <label for="a1525817423666">
            <p>
             0.86
            </p>
           </label>
          </div>
          <div>
           <input id="a1525817440503" name="626423" type="radio" value="a1525817440503"/>
           <label for="a1525817440503">
            <p>
             0.06
            </p>
           </label>
          </div>
          <div>
           <input id="a1525817447287" name="626423" type="radio" value="a1525817447287"/>
           <label for="a1525817447287">
            <p>
             0.16
            </p>
           </label>
          </div>
          <div>
           <input id="a1525817451406" name="626423" type="radio" value="a1525817451406"/>
           <label for="a1525817451406">
            <p>
             0.36
            </p>
           </label>
          </div>
         </form>
         <details>
          <summary>
           <strong>
            SOLUTION:
           </strong>
          </summary>
          0.16
         </details>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <form>
          <fieldset>
           <legend>
            <p>
             What is b?
            </p>
           </legend>
          </fieldset>
          <div>
           <input id="a1525817496539" name="626425" type="radio" value="a1525817496539"/>
           <label for="a1525817496539">
            <p>
             0.86
            </p>
           </label>
          </div>
          <div>
           <input id="a1525817510910" name="626425" type="radio" value="a1525817510910"/>
           <label for="a1525817510910">
            <p>
             0.16
            </p>
           </label>
          </div>
          <div>
           <input id="a1525817514556" name="626425" type="radio" value="a1525817514556"/>
           <label for="a1525817514556">
            <p>
             0.06
            </p>
           </label>
          </div>
          <div>
           <input id="a1525817517776" name="626425" type="radio" value="a1525817517776"/>
           <label for="a1525817517776">
            <p>
             0.36
            </p>
           </label>
          </div>
         </form>
         <details>
          <summary>
           <strong>
            SOLUTION:
           </strong>
          </summary>
          0.06
         </details>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h3 id="transposition">
          Transposition
         </h3>
         <p>
          We've been using the
          <code>
           y = Wx + b
          </code>
          function for our linear function.
         </p>
         <p>
          But there's another function that does the same thing,
          <code>
           y = xW + b
          </code>
          .  These functions do the same thing and are interchangeable, except for the dimensions of the matrices involved.
         </p>
         <p>
          To shift from one function to the other, you simply have to swap the row and column dimensions of each matrix. This is called transposition.
         </p>
         <p>
          For rest of this lesson, we actually use
          <code>
           xW + b
          </code>
          , because this is what TensorFlow uses.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="y = xW + b" class="img img-fluid" src="img/codecogseqn-18.gif"/>
          <figcaption class="figure-caption">
           <p>
            y = xW + b
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          The above example is identical to the quiz you just completed, except that the matrices are transposed.
         </p>
         <p>
          <code>
           x
          </code>
          now has the dimensions 1x3,
          <code>
           W
          </code>
          now has the dimensions 3x2, and
          <code>
           b
          </code>
          now has the dimensions 1x2.  Calculating this will produce a matrix with the dimension of 1x2.
         </p>
         <p>
          You'll notice that the elements in this 1x2 matrix are the same as the elements in the 2x1 matrix from the quiz. Again, these matrices are simply transposed.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/codecogseqn-20.gif"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          We now have our logits!  The columns represent the logits for our two labels.
         </p>
         <p>
          Now you can learn how to train this function in TensorFlow.
         </p>
         <h2 id="weights-and-bias-in-tensorflow">
          Weights and Bias in TensorFlow
         </h2>
         <p>
          The goal of training a neural network is to modify weights and biases to best predict the labels.  In order to use weights and bias, you'll need a Tensor that can be modified.  This leaves out
          <a href="https://www.tensorflow.org/api_docs/python/tf/placeholder" rel="noopener noreferrer" target="_blank">
           <code>
            tf.placeholder()
           </code>
          </a>
          and
          <a href="https://www.tensorflow.org/api_docs/python/tf/constant" rel="noopener noreferrer" target="_blank">
           <code>
            tf.constant()
           </code>
          </a>
          , since those Tensors can't be modified.  This is where
          <a href="https://www.tensorflow.org/api_docs/python/tf/Variable" rel="noopener noreferrer" target="_blank">
           <code>
            tf.Variable
           </code>
          </a>
          class comes in.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h3 id="tfvariable">
          tf.Variable()
         </h3>
         <pre><code class="python language-python">x = tf.Variable(5)</code></pre>
         <p>
          The
          <a href="https://www.tensorflow.org/api_docs/python/tf/Variable" rel="noopener noreferrer" target="_blank">
           <code>
            tf.Variable
           </code>
          </a>
          class creates a tensor with an initial value that can be modified, much like a normal Python variable.  This tensor stores its state in the session, so you must initialize the state of the tensor manually.  You'll use the
          <a href="https://www.tensorflow.org/programmers_guide/variables" rel="noopener noreferrer" target="_blank">
           <code>
            tf.global_variables_initializer()
           </code>
          </a>
          function to initialize the state of all the Variable tensors.
         </p>
         <h5 id="initialization">
          Initialization
         </h5>
         <pre><code>init = tf.global_variables_initializer()
with tf.Session() as sess:
    sess.run(init)</code></pre>
         <p>
          The
          <a href="https://www.tensorflow.org/programmers_guide/variables" rel="noopener noreferrer" target="_blank">
           <code>
            tf.global_variables_initializer()
           </code>
          </a>
          call returns an operation that will initialize all TensorFlow variables from the graph.  You call the operation using a session to initialize all the variables as shown above.  Using the
          <a href="https://www.tensorflow.org/api_docs/python/tf/Variable" rel="noopener noreferrer" target="_blank">
           <code>
            tf.Variable
           </code>
          </a>
          class allows us to change the weights and bias, but an initial value needs to be chosen.
         </p>
         <p>
          Initializing the weights with random numbers from a normal distribution is good practice.  Randomizing the weights helps the model from becoming stuck in the same place every time you train it. You'll learn more about this in the next lesson, when you study gradient descent.
         </p>
         <p>
          Similarly, choosing weights from a normal distribution prevents any one weight from overwhelming other weights.  You'll use the
          <a href="https://www.tensorflow.org/api_docs/python/tf/truncated_normal" rel="noopener noreferrer" target="_blank">
           <code>
            tf.truncated_normal()
           </code>
          </a>
          function to generate random numbers from a normal distribution.
         </p>
         <h3 id="tftruncated_normal">
          tf.truncated_normal()
         </h3>
         <pre><code class="python language-python">n_features = 120
n_labels = 5
weights = tf.Variable(tf.truncated_normal((n_features, n_labels)))</code></pre>
         <p>
          The
          <a href="https://www.tensorflow.org/api_docs/python/tf/truncated_normal" rel="noopener noreferrer" target="_blank">
           <code>
            tf.truncated_normal()
           </code>
          </a>
          function returns a tensor with random values from a normal distribution whose magnitude is no more than 2 standard deviations from the mean.
         </p>
         <p>
          Since the weights are already helping prevent the model from getting stuck, you don't need to randomize the bias.  Let's use the simplest solution, setting the bias to 0.
         </p>
         <h3 id="tfzeros">
          tf.zeros()
         </h3>
         <pre><code class="python language-python">n_labels = 5
bias = tf.Variable(tf.zeros(n_labels))</code></pre>
         <p>
          The
          <a href="https://www.tensorflow.org/api_docs/python/tf/zeros" rel="noopener noreferrer" target="_blank">
           <code>
            tf.zeros()
           </code>
          </a>
          function returns a tensor with all zeros.
         </p>
         <h2 id="linear-classifier-quiz">
          Linear Classifier Quiz
         </h2>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/mnist-012.png"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          You'll be classifying the handwritten numbers
          <code>
           0
          </code>
          ,
          <code>
           1
          </code>
          , and
          <code>
           2
          </code>
          from the MNIST dataset using TensorFlow.  The above is a small sample of the data you'll be training on.  Notice how some of the
          <code>
           1
          </code>
          s are written with a
          <a href="https://en.wikipedia.org/wiki/Serif" rel="noopener noreferrer" target="_blank">
           serif
          </a>
          at the top and at different angles.  The similarities and differences will play a part in shaping the weights of the model.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Left: Weights for labeling 0. Middle: Weights for labeling 1. Right: Weights for labeling 2." class="img img-fluid" src="img/weights-0-1-2.png"/>
          <figcaption class="figure-caption">
           <p>
            Left: Weights for labeling 0. Middle: Weights for labeling 1. Right: Weights for labeling 2.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          The images above are trained weights for each label (
          <code>
           0
          </code>
          ,
          <code>
           1
          </code>
          , and
          <code>
           2
          </code>
          ).  The weights display the unique properties of each digit they have found.  Complete this quiz to train your own weights using the MNIST dataset.
         </p>
         <h3 id="instructions">
          Instructions
         </h3>
         <ol>
          <li>
           Open quiz.py.
           <ol>
            <li>
             Implement
             <code>
              get_weights
             </code>
             to return a
             <a href="https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops/variables#Variable" rel="noopener noreferrer" target="_blank">
              <code>
               tf.Variable
              </code>
             </a>
             of weights
            </li>
            <li>
             Implement
             <code>
              get_biases
             </code>
             to return a
             <a href="https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops/variables#Variable" rel="noopener noreferrer" target="_blank">
              <code>
               tf.Variable
              </code>
             </a>
             of biases
            </li>
            <li>
             Implement
             <code>
              xW + b
             </code>
             in the
             <code>
              linear
             </code>
             function
            </li>
           </ol>
          </li>
          <li>
           Open sandbox.py
           <ol>
            <li>
             Initialize all weights
            </li>
           </ol>
          </li>
         </ol>
         <p>
          Since
          <code>
           xW
          </code>
          in
          <code>
           xW + b
          </code>
          is matrix multiplication, you have to use the
          <a href="https://www.tensorflow.org/api_docs/python/tf/matmul" rel="noopener noreferrer" target="_blank">
           <code>
            tf.matmul()
           </code>
          </a>
          function instead of
          <a href="https://www.tensorflow.org/api_docs/python/tf/multiply" rel="noopener noreferrer" target="_blank">
           <code>
            tf.multiply()
           </code>
          </a>
          .  Don't forget that order matters in matrix multiplication, so
          <code>
           tf.matmul(a,b)
          </code>
          is not the same as
          <code>
           tf.matmul(b,a)
          </code>
          .
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="15. Quiz Linear Function.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('14. TensorFlow Linear Function')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
