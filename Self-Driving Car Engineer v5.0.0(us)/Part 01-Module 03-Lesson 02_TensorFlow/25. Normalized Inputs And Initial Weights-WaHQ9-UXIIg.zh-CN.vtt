WEBVTT
Kind: captions
Language: zh-CN

00:00:00.630 --> 00:00:04.179
在测试题的例子中 数学运算的结果应为 1.0

00:00:04.179 --> 00:00:07.184
但代码运行的结果为 0.95

00:00:07.184 --> 00:00:09.119
这是很大的差异

00:00:09.119 --> 00:00:12.179
你可以试一下 将 1000000000 替换为 1

00:00:12.179 --> 00:00:14.890
会看到误差会变得非常微小

00:00:14.890 --> 00:00:17.660
我们希望 我们所关心的这一巨大的损失函数所涉及的值

00:00:17.660 --> 00:00:22.379
不要太大 也不要太小

00:00:23.379 --> 00:00:28.489
一个较好的指导原则就是 使变量尽可能保持

00:00:28.489 --> 00:00:31.349
0 均值  和相同的方差

00:00:31.350 --> 00:00:34.250
除了有利于值运算之外 在做优化时

00:00:34.250 --> 00:00:39.109
保持 0 均值 和相同的方差

00:00:39.109 --> 00:00:42.200
也有很好的数学理由

00:00:42.200 --> 00:00:45.109
如果问题设计得不好 优化器需要做大量的搜索

00:00:45.109 --> 00:00:48.409
来找到好的解决方案

00:00:48.409 --> 00:00:51.029
如果问题设计得好 那么优化器的工作

00:00:51.030 --> 00:00:53.079
会轻松许多

00:00:53.079 --> 00:00:55.809
如果你处理的是图像 就简单了

00:00:55.810 --> 00:00:59.050
你可以将图像的像素值 通常在 0 到 255

00:00:59.049 --> 00:00:59.759
之间

00:00:59.759 --> 00:01:03.829
减去 128 再除以 128

00:01:03.829 --> 00:01:07.659
它不会改变图像的内容 

00:01:07.659 --> 00:01:09.409
但从数学角度而言 优化会更容易进行

00:01:10.599 --> 00:01:13.780
你还希望 权重和偏差

00:01:13.780 --> 00:01:16.879
有一个理想的初始化值 有利于做梯度下降

00:01:16.879 --> 00:01:20.459
找到好的初始化值的方法琳琅满目

00:01:20.459 --> 00:01:23.989
但我们会重点来看一个简单的通用方法

00:01:23.989 --> 00:01:27.899
从高斯分布上随机获取初始权重

00:01:27.900 --> 00:01:29.140
使这些权重的均值为 0 标准差为 σ

00:01:30.230 --> 00:01:34.350
σ 值决定了在初始化时

00:01:34.349 --> 00:01:37.549
你的输出的数量级

00:01:37.549 --> 00:01:41.829
因为上面还加了 Softmax 函数 其数量级也决定了 

00:01:41.829 --> 00:01:45.560
你的初始概率分布的陡峭程度

00:01:45.560 --> 00:01:49.350
σ 较大 则说明你的分布会集中在峰值处

00:01:49.349 --> 00:01:51.399
表示确定性很强

00:01:51.400 --> 00:01:54.710
σ 较小 则表示你的分布

00:01:54.709 --> 00:01:55.339
确定性很弱

00:01:55.340 --> 00:01:58.980
通常 从确定性弱的分布开始比较好

00:01:58.980 --> 00:02:02.540
然后通过训练 让优化器的确定性越来越强

00:02:02.540 --> 00:02:05.230
所以 初始时取小的 σ 

00:02:05.230 --> 00:02:05.790
好

00:02:05.790 --> 00:02:09.879
我们现在万事俱备 可以训练分类器了

00:02:09.879 --> 00:02:13.537
我们有了训练数据 已经归一化好了 具有 0 均值

00:02:13.538 --> 00:02:15.270
和单位方差

00:02:15.270 --> 00:02:20.230
我们将它乘以一个大的矩阵 即权重随机初始化矩阵

00:02:20.229 --> 00:02:24.409
应用 softmax 函数和交叉熵误差函数

00:02:24.409 --> 00:02:29.409
然后计算此误差在整个训练集上的平均值

00:02:29.409 --> 00:02:31.990
然后用我们神奇的优化工具

00:02:31.990 --> 00:02:36.735
对误差函数求权重和偏差的偏导

00:02:36.735 --> 00:02:40.965
根据导数值反向调整一步

00:02:40.965 --> 00:02:42.215
再重做一遍

00:02:42.215 --> 00:02:45.495
重复此过程 直到获得误差函数的最小值

