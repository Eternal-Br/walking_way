WEBVTT
Kind: captions
Language: zh-CN

00:00:00.470 --> 00:00:01.970
现在你已经训练了你的第一个模型

00:00:01.970 --> 00:00:04.799
有一些非常重要的方面我想讲一下

00:00:04.799 --> 00:00:08.129
你可能在作业中看到了 我们有一个训练集、

00:00:08.130 --> 00:00:11.530
一个验证集和一个测试集

00:00:11.529 --> 00:00:13.299
这些都是干什么用的？

00:00:13.300 --> 00:00:14.380
不要跳过那部分

00:00:14.380 --> 00:00:17.109
它们用于衡量你训练的模型的性能

00:00:17.109 --> 00:00:19.559
但不会让你搬起石头砸自己的脚

00:00:19.559 --> 00:00:22.299
这比你最初认为的要微妙得多

00:00:22.300 --> 00:00:25.500
这也非常重要 因为我们稍后会发现

00:00:25.500 --> 00:00:28.519
一旦你知道如何衡量解决方案的表现时

00:00:28.519 --> 00:00:30.789
问题便已经解决了一半

00:00:30.789 --> 00:00:33.560
我来解释一下为什么衡量模型性能是一件很微妙的事情

00:00:33.560 --> 00:00:35.870
我们回到分类任务

00:00:35.869 --> 00:00:38.459
你有一堆带有标签的图像

00:00:38.460 --> 00:00:42.560
你可以用你的分类器对它们进行分类

00:00:42.560 --> 00:00:44.170
看看有多少是正确分类的

00:00:44.170 --> 00:00:45.560
这是我错误分类的数量

00:00:45.560 --> 00:00:48.800
然后又对新的图像使用你的分类器

00:00:48.799 --> 00:00:51.199
你之前从未见过的图像

00:00:51.200 --> 00:00:54.810
看看有多少分类正确 会发现效果变差了

00:00:54.810 --> 00:00:56.929
分类器没能很好分类

00:00:56.929 --> 00:00:57.554
发生了什么呢？

00:00:57.554 --> 00:01:02.369
想象我构建了一个分类器 用于比较新图像

00:01:02.369 --> 00:01:06.829
与训练集中见到过的任何其他图像

00:01:06.829 --> 00:01:08.530
并返回标签值

00:01:08.530 --> 00:01:11.500
根据我们之前对这一分类器的定义

00:01:11.500 --> 00:01:14.689
它在训练集上可以达到 100% 的准确度

00:01:14.689 --> 00:01:17.950
但只要看到一个新图片 它就不知所措了

00:01:17.950 --> 00:01:19.829
它不知道该怎么做

00:01:19.829 --> 00:01:21.579
所以这个分类器是失败的

00:01:21.579 --> 00:01:25.409
它的问题在于 分类器只是记住了训练集的内容

00:01:25.409 --> 00:01:28.079
却不能泛化到新示例上

00:01:28.079 --> 00:01:30.280
这不仅仅是一个理论问题

00:01:30.280 --> 00:01:33.390
你构建的每个分类器都有试图

00:01:33.390 --> 00:01:35.250
记住训练集的倾向

00:01:35.250 --> 00:01:37.750
而且通常都会记得很好

00:01:37.750 --> 00:01:42.280
但你的任务就是 帮助它泛化到新数据上

00:01:42.280 --> 00:01:45.560
那么 我们如何衡量分类器的泛化水平 而不是衡量

00:01:45.560 --> 00:01:48.590
它对数据的记忆程度呢？

00:01:48.590 --> 00:01:52.620
最简单的方法是取训练集的一小部分

00:01:52.620 --> 00:01:56.090
训练时完全不要碰它们 而是作为测试数据 用来测量误差

00:01:57.170 --> 00:01:59.989
问题就解决了 因为你的分类器无法再作弊了

00:01:59.989 --> 00:02:03.717
它没有看到过测试数据 也就无法记住它们了

00:02:03.718 --> 00:02:04.859
但仍然有一个问题

00:02:04.859 --> 00:02:08.949
因为训练分类器通常是一个反复试错的过程

00:02:08.949 --> 00:02:12.190
你先试着调了一个分类器 衡量它的性能

00:02:12.189 --> 00:02:14.859
然后又试着调了一个 再衡量

00:02:14.860 --> 00:02:19.500
一个又一个 你调整模型 摸索参数

00:02:19.500 --> 00:02:23.759
测量 最终得到了你认为的完美分类器

00:02:24.800 --> 00:02:28.500
在你精心安排下 测试数据始终与训练数据分开

00:02:28.500 --> 00:02:32.610
确保只在测试数据上测量性能

00:02:32.610 --> 00:02:35.530
现在 你将它部署到实战环境中

00:02:35.530 --> 00:02:39.520
会有更多数据 然后衡量它在新数据上的表现

00:02:39.520 --> 00:02:42.010
但结果差强人意

00:02:42.009 --> 00:02:43.979
原因何在呢？

00:02:43.979 --> 00:02:48.579
那就是你的分类器通过你自己的眼睛间接地

00:02:48.580 --> 00:02:49.910
看到了测试数据

00:02:49.909 --> 00:02:54.009
每次当你决定使用什么分类器 调整哪些参数时

00:02:54.009 --> 00:02:59.090
你实际上在向分类器透露测试集的信息

00:02:59.090 --> 00:03:01.610
虽然每次只是一点点 但积少成多

00:03:01.610 --> 00:03:03.560
所以随着时间的推移 当你跑了很多次试验后

00:03:03.560 --> 00:03:07.629
你的测试数据便渗透进了训练数据

00:03:07.629 --> 00:03:09.150
那你可以做什么呢？

00:03:09.150 --> 00:03:11.120
处理的方式有很多种

00:03:11.120 --> 00:03:12.610
我教给大家最简单的一个方法

00:03:12.610 --> 00:03:16.340
再在训练集中取一部分 将它藏起来

00:03:16.340 --> 00:03:19.340
永远不要看它 直到你做出了最终决定

00:03:19.340 --> 00:03:23.460
你可以使用验证集来衡量实际误差

00:03:23.460 --> 00:03:26.870
或许验证集会融入到训练集中

00:03:26.870 --> 00:03:29.870
但没关系 你始终可以依靠这个测试集

00:03:29.870 --> 00:03:32.509
来测量分类器的实际性能

