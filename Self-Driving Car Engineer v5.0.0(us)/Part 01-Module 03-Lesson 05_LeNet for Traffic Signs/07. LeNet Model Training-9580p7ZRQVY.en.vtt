WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.134
Great! Now that everything else is set up,

00:00:03.134 --> 00:00:06.359
we can build a function to train and validate our model.

00:00:06.360 --> 00:00:11.850
First, we create the TensorFlow session and initialize the variables.

00:00:11.849 --> 00:00:16.454
We train over whatever number of epochs has been set in the EPOCHS hyperparameter.

00:00:16.454 --> 00:00:18.404
At the beginning of each epoch,

00:00:18.405 --> 00:00:20.730
we shuffle our training data to ensure that

00:00:20.730 --> 00:00:23.730
our training isn't biased by the order of the images.

00:00:23.730 --> 00:00:28.750
Then, we break our training data into batches and train the model on each batch.

00:00:28.750 --> 00:00:30.329
At the end of each epoch,

00:00:30.329 --> 00:00:33.269
we evaluate the model on our validation data.

00:00:33.270 --> 00:00:36.359
Once we have completely trained the model, we save it.

00:00:36.359 --> 00:00:39.119
That way, we can load it up later and modify

00:00:39.119 --> 00:00:42.539
it or evaluate the model on our test dataset.

00:00:42.539 --> 00:00:44.179
As we train the model,

00:00:44.179 --> 00:00:48.570
we see that the validation accuracy starts off really high and stays there.

00:00:48.570 --> 00:00:53.359
Partly, this is the result of a powerful convolutional network architecture like LeNet,

00:00:53.359 --> 00:00:57.750
and partly, this is because we've already chosen good hyperparameters.

00:00:57.750 --> 00:00:59.549
When you experiment with your own models,

00:00:59.549 --> 00:01:01.604
you'll probably have to spend a fair bit of time

00:01:01.604 --> 00:01:04.439
tuning the hyperparameters to give the best results.

