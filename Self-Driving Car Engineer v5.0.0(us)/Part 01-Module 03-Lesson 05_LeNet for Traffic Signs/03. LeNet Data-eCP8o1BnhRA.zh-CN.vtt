WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.980
在第一个代码单元格中 我们读取了

00:00:01.980 --> 00:00:05.515
TensorFlow 中预置的 MNIST 数据集

00:00:05.514 --> 00:00:09.160
然后 我们分别保存 训练数据集 交叉验证数据集 和测试数据集

00:00:09.160 --> 00:00:11.910
接下来 我们验证 每个数据集中的

00:00:11.910 --> 00:00:15.265
图片数量与同一数据集中的标签数量相匹配

00:00:15.265 --> 00:00:16.740
然后 我们打印出图像的维度信息

00:00:16.739 --> 00:00:20.339
这样我们就知道了数据的维度

00:00:20.339 --> 00:00:23.429
最后 我们打印出每个数据集的数据量

00:00:23.429 --> 00:00:24.850
运行代码

00:00:24.850 --> 00:00:28.500
我们可以看到 训练集里有 55,000 张图像

00:00:28.500 --> 00:00:34.130
交叉验证集里有 5,000 张图像 测试集里有 10,000 张图像

00:00:34.130 --> 00:00:37.570
在下面的代码单元格里 我们把 28x28 的

00:00:37.570 --> 00:00:43.259
MNIST 图像转换为 32x32 的图像 这样 LeNet 就可以处理它们了

00:00:43.259 --> 00:00:48.439
我们可以通过图像处理软件放大每张图像

00:00:48.439 --> 00:00:52.159
但在这里 我们只需把边缘附近多出的像素点填充为零

00:00:52.159 --> 00:00:55.234
这样速度更快 并且效果很好

00:00:55.234 --> 00:00:58.950
完成后 图像形状就变成了 32x32x1

00:00:58.950 --> 00:01:02.710
这正是 LeNet 的输入尺寸

00:01:02.710 --> 00:01:05.310
此外 通过数据的可视化 确保模型的运转

00:01:05.310 --> 00:01:08.790
和我们的预期一致 是一个非常好的想法

00:01:08.790 --> 00:01:11.920
在本例中 我们从训练集中随机选出一幅图片

00:01:11.920 --> 00:01:15.969
然后使用 matplotlib 将其可视化

00:01:15.969 --> 00:01:19.170
然后 我们还打印出了该图像的标签

00:01:19.170 --> 00:01:24.105
很好 这一标签和图像相互匹配

00:01:24.105 --> 00:01:26.410
在下个单元格中 我们对数据进行了预处理

00:01:26.409 --> 00:01:30.489
在本例中 我们仅仅是打乱了训练集数据的顺序

00:01:30.489 --> 00:01:33.670
打乱训练集数据的顺序是十分必要的 否则

00:01:33.670 --> 00:01:37.000
数据的顺序可能对网络的性能产生巨大影响

