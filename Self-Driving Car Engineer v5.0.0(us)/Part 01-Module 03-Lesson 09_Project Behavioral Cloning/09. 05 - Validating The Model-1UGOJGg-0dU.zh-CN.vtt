WEBVTT
Kind: captions
Language: zh-CN

00:00:00.060 --> 00:00:01.684
为了在我的本地计算机上

00:00:01.683 --> 00:00:04.019
以无人驾驶模式运行模拟器

00:00:04.019 --> 00:00:07.530
我首先需要克隆项目的 GitHub 代码库

00:00:07.530 --> 00:00:10.470
这个库里包含 drive.py 文件

00:00:10.470 --> 00:00:12.510
用来加载我已经保存的模型

00:00:12.509 --> 00:00:14.189
并用它来预测转向角

00:00:14.189 --> 00:00:17.609
下面 我把保存的模型从 AWS 实例中

00:00:17.609 --> 00:00:22.079
保存到本地 然后运行 drive.py

00:00:22.079 --> 00:00:23.859
把我的模型以参数形式导入

00:00:23.859 --> 00:00:26.759
drive.py 现在正在运行 并在等待模拟器

00:00:26.760 --> 00:00:28.500
启动无人驾驶模式

00:00:28.500 --> 00:00:30.390
这一次启动模拟器时

00:00:30.390 --> 00:00:32.259
我会选择无人驾驶模式

00:00:32.259 --> 00:00:34.570
我可以从模拟器的输出看到 drive.py

00:00:34.570 --> 00:00:37.530
已经根据我的模型成功预测了转向角

00:00:37.530 --> 00:00:39.899
这非常棒

00:00:39.899 --> 00:00:42.269
我还可以看到 汽车行驶得很糟糕

00:00:42.270 --> 00:00:43.507
这就不那么棒了

00:00:43.506 --> 00:00:45.089
车速并不快 因为大多数时间

00:00:45.090 --> 00:00:48.100
它都在左右摇摆

00:00:48.100 --> 00:00:49.859
实际上 这是个不错的开头

00:00:49.859 --> 00:00:52.200
这个神经网络的无人驾驶效果不太好

00:00:52.200 --> 00:00:53.400
不过我本来的预期也没那么高

00:00:53.399 --> 00:00:55.109
我真正想要做的

00:00:55.109 --> 00:00:57.700
是验证以下整个流程是可行的

00:00:57.700 --> 00:01:01.080
包括训练模型、保存模型 并使用该模型在模拟器中驾驶车辆

00:01:01.079 --> 00:01:04.819
既然所有环节都能走得通 我们现在开始改进模型吧

