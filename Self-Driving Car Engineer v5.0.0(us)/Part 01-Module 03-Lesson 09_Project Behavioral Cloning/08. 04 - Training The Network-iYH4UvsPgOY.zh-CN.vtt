WEBVTT
Kind: captions
Language: zh-CN

00:00:00.090 --> 00:00:01.881
用 GPU 来处理模拟器生成的图像数据

00:00:01.881 --> 00:00:04.320
要比使用 CPU 来处理

00:00:04.320 --> 00:00:05.520
容易得多

00:00:05.519 --> 00:00:10.169
这里 我启动了一个可使用 GPU 进行计算加速的 AWS EC2 实例

00:00:10.169 --> 00:00:12.719
准备在这个实例上训练网络

00:00:12.720 --> 00:00:16.170
我会先使用 SCP 把数据传输到 EC2 实例

00:00:16.170 --> 00:00:19.090
然后在那上面提取数据

00:00:19.089 --> 00:00:22.780
接下来 我使用 Python 的 CSV 库读取并存储

00:00:22.780 --> 00:00:26.620
drivinglog.csv 文件

00:00:26.620 --> 00:00:29.769
而后 从每行数据提取每个摄像头拍摄图像的路径

00:00:29.769 --> 00:00:33.189
但请记住 这些路径是我本地机器上的路径

00:00:33.189 --> 00:00:35.629
现在 我要在 AWS 实例上运行

00:00:35.630 --> 00:00:38.170
所以我需要更新路径

00:00:38.170 --> 00:00:40.590
保证路径在 AWS 实例上是有效的

00:00:40.590 --> 00:00:42.420
有一种方法可以轻松更新路径

00:00:42.420 --> 00:00:44.670
就是在斜杠（'/'）处分割路径

00:00:44.670 --> 00:00:46.560
然后提取最后一个斜杠后的内容

00:00:46.560 --> 00:00:47.940
这部分就是文件名

00:00:47.939 --> 00:00:50.159
接下来 我就可以把这些文件名添加到

00:00:50.159 --> 00:00:51.959
AWS 实例上的

00:00:51.960 --> 00:00:53.969
图像目录路径的末尾

00:00:53.969 --> 00:00:55.679
一旦获取了当前路径 我就可以

00:00:55.679 --> 00:00:59.340
使用 OpenCV 加载图像

00:00:59.340 --> 00:01:00.850
加载图像后 我就能

00:01:00.850 --> 00:01:03.380
把它添加到图像列表中

00:01:03.380 --> 00:01:05.900
可以利用类似操作导入转向角数据

00:01:05.900 --> 00:01:07.772
然后把它们用作输出标签

00:01:07.772 --> 00:01:09.980
加载转向角数据实际上更简单一些

00:01:09.980 --> 00:01:13.549
因为不需要处理路径或图像

00:01:13.549 --> 00:01:16.670
我只需从 CSV 文件的行中提取第四列内容

00:01:16.670 --> 00:01:18.477
然后将其数据格式转换为浮点型

00:01:18.477 --> 00:01:20.060
这样即可获得这个时间点上的

00:01:20.060 --> 00:01:21.500
转向角数据

00:01:21.500 --> 00:01:24.079
接下来 我把这些转向角数据添加到测量数据集内

00:01:24.079 --> 00:01:26.670
就像对图像的操作一样

00:01:26.670 --> 00:01:29.480
现在 我已经加载了图像和转向角数据

00:01:29.480 --> 00:01:31.850
我把它们的格式转换为 NumPy 矩阵

00:01:31.849 --> 00:01:34.579
因为这是 Keras 要求的数据格式

00:01:34.579 --> 00:01:37.310
下面 我来搭建一个尽可能简单的神经网络

00:01:37.310 --> 00:01:40.129
只是为了确保整个流程的运行没有问题

00:01:40.129 --> 00:01:42.949
这个网络只是一个从扁平化的图像

00:01:42.950 --> 00:01:44.450
到单一输出节点的连接

00:01:44.450 --> 00:01:46.280
这个单一的输出节点会预测转向角

00:01:46.280 --> 00:01:49.969
因此这个网络是一个回归网络

00:01:49.969 --> 00:01:51.980
对于分类网络

00:01:51.980 --> 00:01:55.579
需要在输出层后添加了一个 softmax 激活函数

00:01:55.579 --> 00:01:57.649
但在这种回归网络里

00:01:57.650 --> 00:02:00.230
我只需要这个单一的输出节点来直接预测

00:02:00.230 --> 00:02:01.430
转向角大小

00:02:01.430 --> 00:02:05.230
因此 我在这里不用任何激活函数

00:02:05.230 --> 00:02:08.288
网络搭建好后 就可以编译这个模型了

00:02:08.288 --> 00:02:12.130
我选择均方误差作为损失函数

00:02:12.129 --> 00:02:14.229
这和我们之前用过的交叉熵函数不同

00:02:14.229 --> 00:02:16.599
因为这是一个回归网络

00:02:16.599 --> 00:02:19.689
不是分类网络

00:02:19.689 --> 00:02:22.960
这里我想做的是

00:02:22.960 --> 00:02:25.270
尽量降低网络的预测值和真实数值

00:02:25.270 --> 00:02:26.590
之间的误差

00:02:26.590 --> 00:02:29.379
这种情况下 均方误差是一种理想的损失函数

00:02:29.379 --> 00:02:32.019
模型编译完成后 就可以使用之前导入的特征和标签数据来训练模型

00:02:32.020 --> 00:02:35.590
同样地 我会打乱数据的顺序

00:02:35.590 --> 00:02:40.120
并留出 20% 的数据作为验证集

00:02:40.120 --> 00:02:43.360
最后 保存好训练完的模型

00:02:43.360 --> 00:02:45.520
稍后就可以下载到本地计算机上

00:02:45.520 --> 00:02:47.740
并查看它在模拟器中自动驾驶的表现

00:02:47.740 --> 00:02:50.020
我们开始训练模型 看看情况如何

00:02:50.020 --> 00:02:52.600
默认情况下 Keras 会训练 10 轮

00:02:52.599 --> 00:02:54.430
我可以看到 验证数据集的损失函数值

00:02:54.430 --> 00:02:56.379
在前7轮是不断下降的

00:02:56.379 --> 00:02:58.539
而后开始上升

00:02:58.539 --> 00:03:01.900
这说明可能发生了训练数据的过拟合

00:03:01.900 --> 00:03:03.520
现在看起来好了一点

00:03:03.520 --> 00:03:06.070
几乎所有轮数的验证集损失函数值

00:03:06.069 --> 00:03:07.129
都在降低

00:03:07.129 --> 00:03:09.729
接下去 我会把这个训练好的模型下载到本地计算机上

00:03:09.729 --> 00:03:13.500
并查看它在模拟器中自动驾驶的表现如何

