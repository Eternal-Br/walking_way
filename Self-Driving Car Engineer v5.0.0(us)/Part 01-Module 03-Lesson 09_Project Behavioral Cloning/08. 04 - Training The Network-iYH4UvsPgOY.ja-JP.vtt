WEBVTT
Kind: captions
Language: ja-JP

00:00:00.090 --> 00:00:01.881
シミュレーターからのイメージデータは

00:00:01.881 --> 00:00:04.320
CPUよりGPUで操作する方が

00:00:04.320 --> 00:00:05.520
はるかに容易になります

00:00:05.519 --> 00:00:10.169
そこで GPUをアタッチしてAWS EC2インスタンスを起動しました

00:00:10.169 --> 00:00:12.719
そこでネットワークをトレーニングします

00:00:12.720 --> 00:00:16.170
SCPを使用してデータをEC2インスタンスにコピーし

00:00:16.170 --> 00:00:19.090
そこでデータを抽出します

00:00:19.089 --> 00:00:22.780
次にPython CSVライブラリーを使用して

00:00:22.780 --> 00:00:26.620
drivinglog.csvファイルから行を読み取って保存し

00:00:26.620 --> 00:00:29.769
行ごとにカメラ画像へのパスを抽出します

00:00:29.769 --> 00:00:33.189
しかしパスはローカルマシンに記録されています

00:00:33.189 --> 00:00:35.629
今度はAWSインスタンスを使っています

00:00:35.630 --> 00:00:38.170
そこでパスを更新して

00:00:38.170 --> 00:00:40.590
AWSインスタンスで有効にする必要があります

00:00:40.590 --> 00:00:42.420
パスを更新する簡単な方法は

00:00:42.420 --> 00:00:44.670
パスをスラッシュで分割し

00:00:44.670 --> 00:00:46.560
最後のトークンを抽出します

00:00:46.560 --> 00:00:47.940
これがファイル名になります

00:00:47.939 --> 00:00:50.159
こうすると そのファイル名をAWSインスタンス上の

00:00:50.159 --> 00:00:51.959
画像ディレクトリへのパスの

00:00:51.960 --> 00:00:53.969
最後に追加できます

00:00:53.969 --> 00:00:55.679
現在パスができたら

00:00:55.679 --> 00:00:59.340
OpenCVを使用して画像を読み込むことができます

00:00:59.340 --> 00:01:00.850
そして 画像を読み込んだら

00:01:00.850 --> 00:01:03.380
それを画像リストに追加できます

00:01:03.380 --> 00:01:05.900
出力ラベルとして役立つステアリング角の

00:01:05.900 --> 00:01:07.772
測定値に対しても同様のことができます

00:01:07.772 --> 00:01:09.980
実際 このステアリング測定を読み込むのは簡単です

00:01:09.980 --> 00:01:13.549
処理しなければならないパスや画像はないからです

00:01:13.549 --> 00:01:16.670
CSV行から4番目のトークンを抽出して

00:01:16.670 --> 00:01:18.477
浮動小数点としてキャストするだけです

00:01:18.477 --> 00:01:20.060
これでこのポイントのステアリング角の測定値が

00:01:20.060 --> 00:01:21.500
わかります

00:01:21.500 --> 00:01:24.079
次に、その測定値をより大きな測定配列に追加します

00:01:24.079 --> 00:01:26.670
画像と同じように

00:01:26.670 --> 00:01:29.480
画像とステアリング測定を読み込んだので

00:01:29.480 --> 00:01:31.850
これらをNumPy配列に変換します

00:01:31.849 --> 00:01:34.579
それがKerasに必要な形式だからです

00:01:34.579 --> 00:01:37.310
次に 可能な限り最も基本的なニューラルネットワークを構築して

00:01:37.310 --> 00:01:40.129
すべてが機能していることを確認します

00:01:40.129 --> 00:01:42.949
このネットワークは1つの出力ノードに接続された

00:01:42.950 --> 00:01:44.450
フラット化されたイメージになります

00:01:44.450 --> 00:01:46.280
この単一の出力ノードは

00:01:46.280 --> 00:01:49.969
ステアリング角度を予測し それがこの回帰ネットワークを作ります

00:01:49.969 --> 00:01:51.980
分類ネットワークの場合は

00:01:51.980 --> 00:01:55.579
softmaxアクティベーション関数を出力層に適用します

00:01:55.579 --> 00:01:57.649
しかし このような回帰ネットワークでは

00:01:57.650 --> 00:02:00.230
単一の出力ノードで

00:02:00.230 --> 00:02:01.430
ステアリング角度を直接予測したいだけです

00:02:01.430 --> 00:02:05.230
そのため ここではアクティベーション関数を適用しません

00:02:05.230 --> 00:02:08.288
ネットワークが構築できたので モデルをコンパイルします

00:02:08.288 --> 00:02:12.130
損失関数として平均二乗誤差 すなわちMSEを使用します

00:02:12.129 --> 00:02:14.229
これは以前使用した

00:02:14.229 --> 00:02:16.599
クロスエントロピー関数とは違い また これは

00:02:16.599 --> 00:02:19.689
分類ネットワークではなく回帰ネットワークだからです

00:02:19.689 --> 00:02:22.960
やりたいことは、ネットワークが予測するステアリング角の測定値と

00:02:22.960 --> 00:02:25.270
検証データの測定値の間の誤差を

00:02:25.270 --> 00:02:26.590
最小化することです

00:02:26.590 --> 00:02:29.379
平均二乗誤差は これに適した損失関数です

00:02:29.379 --> 00:02:32.019
モデルがコンパイルできたら 今構築した機能および

00:02:32.020 --> 00:02:35.590
ラベルでトレーニングします  またデータをシャッフルして

00:02:35.590 --> 00:02:40.120
データの20％を切り離して 評価セットとして使用します

00:02:40.120 --> 00:02:43.360
最後にトレーニング済みのモデルを保存して 後で

00:02:43.360 --> 00:02:45.520
ローカルマシンにダウンロードして

00:02:45.520 --> 00:02:47.740
シミュレーターの運転に使えるかどうか確認します

00:02:47.740 --> 00:02:50.020
モデルをトレーニングしてみましょう

00:02:50.020 --> 00:02:52.600
デフォルトでは Kerasは10エポックの間トレーニングします

00:02:52.599 --> 00:02:54.430
最初の7エポックで

00:02:54.430 --> 00:02:56.379
検証損失の減少を見てから

00:02:56.379 --> 00:02:58.539
再開できます

00:02:58.539 --> 00:03:01.900
これは おそらくトレーニングデータをオーバーフィッティングしているサインです

00:03:01.900 --> 00:03:03.520
これで少しは良くなりましたね

00:03:03.520 --> 00:03:06.070
今度は検証損失がエポックのほぼすべてで

00:03:06.069 --> 00:03:07.129
減少しています

00:03:07.129 --> 00:03:09.729
次にこのモデルをローカルマシンにダウンロードして

00:03:09.729 --> 00:03:13.500
シミュレーターでうまく運転できるか確認します

