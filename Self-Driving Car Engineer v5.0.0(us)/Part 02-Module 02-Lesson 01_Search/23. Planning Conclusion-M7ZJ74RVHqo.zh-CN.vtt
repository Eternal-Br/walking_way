WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.000
画面上展示的是我们的斯坦福赛车 Junior 正在行驶

00:00:05.000 --> 00:00:10.000
应用了与真正驾驶同样的算法

00:00:10.000 --> 00:00:17.000
这里你能看到它正在执行右转动作 然后是变道操作

00:00:17.000 --> 00:00:20.000
这些是不连续动作 该车真实地执行了这些动作

00:00:20.000 --> 00:00:23.000
并成功到达了橙色圆环处的目的地·

00:00:23.000 --> 00:00:28.000
但是 如果我们让换道操作变得代价特别大

00:00:28.000 --> 00:00:31.000
就像之前我们对左转操作所做的一样

00:00:31.000 --> 00:00:34.000
那么该车会选择不同的路径

00:00:34.000 --> 00:00:41.000
它会先直行 然后左转 这种操作相对代价不大

00:00:41.000 --> 00:00:46.000
然后该车会左转 再左转

00:00:46.000 --> 00:00:51.000
直到它和目标处于同一车道内

00:00:51.000 --> 00:00:57.000
这是在我们的动态规划算法之内修改成本函数的结果

00:00:57.000 --> 00:01:02.000
大家刚学习过 该算法使用3个维度来计算 大家也刚对其进行了编程

00:01:02.000 --> 00:01:07.000
你们编写的程序可以有效驱动该车 并且通过修改这些成本函数

00:01:07.000 --> 00:01:11.000
该车也可以以一种优化方式到达目的地 正如大家所见

00:01:11.000 --> 00:01:16.000
优化方式与你赋予的成本值有关

00:01:16.000 --> 00:01:19.000
祝贺大家 你们已经学习了我的第一节运动课程

00:01:19.000 --> 00:01:22.000
本课程中 我们假定世界是离散的

00:01:22.000 --> 00:01:28.000
我们学习了2种规划算法 第一种是 A-star 它使用一种启发式搜索来发现路径

00:01:28.000 --> 00:01:33.000
第二种是动态规划算法 它会发现一个整体的策略 策略中包含到任意一点的路径

00:01:33.000 --> 00:01:35.000
而且两种算法我们都实现了

00:01:35.000 --> 00:01:40.000
事实上 在有关策略的例子里 即使是使用三个维度 这都是很了不起的成绩

00:01:40.000 --> 00:01:42.000
所以 我会祝贺大家的努力

00:01:42.000 --> 00:01:45.000
你们确实已经理解了两种主流的范式

00:01:45.000 --> 00:01:48.000
通过它们 我们的机器人便可以进行运动决策了

00:01:48.000 --> 00:01:52.000
这两种算法通常也是人工智能相关的主要范式

00:01:52.000 --> 00:01:58.000
下节课中 我们会讲到如何把这些知识应用到真正的机器人运动中

00:01:58.000 --> 00:02:04.000
我们会讲到连续状态空间 也会讲到什么是“控制”

00:02:04.000 --> 00:02:08.000
通过控制 我们可以让机器人活动起来 下周再见

