WEBVTT
Kind: captions
Language: ja

00:00:00.000 --> 00:00:04.000
今回は計画の代替手法に関する講義です

00:00:04.000 --> 00:00:09.000
この代替手法にはたくさんの長所と短所があります

00:00:09.000 --> 00:00:14.000
ダイナミック・プログラミングと呼ばれ
A＊と同様に最短経路を探索します

00:00:14.000 --> 00:00:20.000
A＊と同様に環境の地図を指定し
ゴール位置は1つまたは複数でも指定できます

00:00:20.000 --> 00:00:22.000
まずゴール位置は1つだけと仮定しましょう

00:00:22.000 --> 00:00:26.000
出力結果は任意の出発地からの最適経路です

00:00:26.000 --> 00:00:30.000
この計画手法は
1つの出発地に限定されるのではなく

00:00:30.000 --> 00:00:35.000
どの出発地でも可能です
これはなぜ重要なのでしょうか？

00:00:35.000 --> 00:00:37.000
例を挙げてみましょう

00:00:37.000 --> 00:00:43.000
あなたはこのような環境にいる
Googleの自動運転車だとします

00:00:43.000 --> 00:00:47.000
小さな通りのこの位置にいて右折を指示されます

00:00:47.000 --> 00:00:50.000
ゴールはここです

00:00:50.000 --> 00:00:54.000
これまでのように2種類の車線があります

00:00:54.000 --> 00:00:57.000
左折車線と直進車線です

00:00:57.000 --> 00:01:00.000
直進車線に進むとゴールまでの道は

00:01:00.000 --> 00:01:04.000
このブロックを一周してこの方向に進む道だけです

00:01:04.000 --> 00:01:06.000
この例は以前に説明しました

00:01:06.000 --> 00:01:09.000
今回私が説明したいのは別の点です

00:01:09.000 --> 00:01:15.000
ここで車線変更しようとすると
失敗する可能性があります　なぜでしょうか？

00:01:15.000 --> 00:01:21.000
車線のここにとても大きなトラックが
いるかもしれません

00:01:21.000 --> 00:01:26.000
トラックがいなくなるまで待とうと
右側の車線に入ると

00:01:26.000 --> 00:01:31.000
あなたの後ろでクラクションを鳴らす人がいます

00:01:31.000 --> 00:01:34.000
トラックがいなくなるまで待つのは嫌ですね

00:01:34.000 --> 00:01:40.000
つまり環境は確率論的で
動作の結果は非決定論的です

00:01:40.000 --> 00:01:45.000
これまでの計画ではそれを無視しましたが
現実では起こり得ます

00:01:45.000 --> 00:01:50.000
現実ではどうして私はここにいるんだ？と
思うかもしれません

00:01:50.000 --> 00:01:54.000
それは世界が確率論的だから起こるのです

00:01:54.000 --> 00:01:57.000
またこのトラックがあなたを入れなかったからです

00:01:57.000 --> 00:02:02.000
つまりあなたには可能性が最も高い
位置の計画だけではなく

00:02:02.000 --> 00:02:05.000
同様に別の位置の計画も必要かもしれません

00:02:05.000 --> 00:02:10.000
ダイナミック・プログラミングが可能にするのは
あらゆる位置の計画です

00:02:10.000 --> 00:02:14.000
この環境をゴール地点と特定の障害物を含む

00:02:14.000 --> 00:02:19.000
グリッドとして描き直すと
ダイナミック・プログラミングは

00:02:19.000 --> 00:02:26.000
すべてのグリッドセルで
最適な動作を行うことを可能にします

00:02:26.000 --> 00:02:29.000
ご覧のとおり各グリッドセルに
ラベルがついています

00:02:29.000 --> 00:02:32.000
ラベルはよくポリシーと呼ばれます

00:02:32.000 --> 00:02:39.000
ポリシーはグリッドセルを
動作にマッピングする関数です

00:02:39.000 --> 00:02:44.000
このケースでは左、下、
右、上への移動の各動作です

00:02:44.000 --> 00:02:51.000
これからダイナミック・プログラミングを用いて
ポリシーを計算します

00:02:51.000 --> 00:02:55.000
つまりこのようなグリッド世界と
ゴール状態を指定され

00:02:55.000 --> 00:03:00.000
ロボットがその位置で選択すべき最適な動作を

00:03:00.000 --> 00:03:05.000
各グリッドセルに出力するソフトウェアを
プログラミングします

00:03:05.000 --> 00:03:10.000
このためにはA＊とは別のさらに計算が必要な
コンピュータアルゴリズムが不可欠です

00:03:10.000 --> 00:03:15.000
これがロボット経路計画のための
ダイナミック・プログラミングです

