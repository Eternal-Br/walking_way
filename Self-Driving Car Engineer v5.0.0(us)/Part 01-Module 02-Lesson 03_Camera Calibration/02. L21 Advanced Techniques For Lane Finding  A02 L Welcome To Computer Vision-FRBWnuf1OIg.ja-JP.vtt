WEBVTT
Kind: captions
Language: ja-JP

00:00:00.000 --> 00:00:02.384
コンピュータービジョンにようこそ

00:00:02.384 --> 00:00:06.410
ロボットは基本的に 3 ステップのサイクルに分けることができます

00:00:06.410 --> 00:00:09.974
第 1 のステップで周りの世界を感知したり知覚します

00:00:09.974 --> 00:00:14.564
第 2 のステップでその認知に基づいて対応を決定します

00:00:14.564 --> 00:00:19.545
第 3 のステップでその決定を遂行するためにアクションを実行します

00:00:19.545 --> 00:00:24.720
コンピュータービジョンは このサイクルでの認知ステップの主要部分です

00:00:24.719 --> 00:00:26.304
Sebastian に尋ねれば

00:00:26.304 --> 00:00:31.280
彼は自動運転車を作るという課題の 80% は認知だと答えるでしょう

00:00:31.280 --> 00:00:33.774
このモジュールでは認知のすべてを扱います

00:00:33.774 --> 00:00:36.129
コンピュータービジョンとは 技術であり

00:00:36.130 --> 00:00:39.380
周りの世界を画像から知覚して理解する術にあたります

00:00:39.380 --> 00:00:41.125
自動運転車の場合

00:00:41.125 --> 00:00:43.435
コンピュータービジョンが車線標示

00:00:43.435 --> 00:00:48.175
車両 歩行者などの要素を環境から検出して安全な走行を実現します

00:00:48.174 --> 00:00:49.679
後ほどこの Nanodegree プログラムで

00:00:49.679 --> 00:00:52.795
レーザーとレーダーのデータを認知のタスクに使用します

00:00:52.795 --> 00:00:55.120
そこでこう尋ねるかもしれません  なぜこんな面倒なことを

00:00:55.119 --> 00:00:58.879
カメラ画像でやるのか  もっと高度な機器が自由に使えるときに

00:00:58.880 --> 00:01:00.775
なぜこんなことをしているんですか David

00:01:00.774 --> 00:01:05.890
良い質問ですね  自動運転車は高度なセンサー一式を利用していますが

00:01:05.890 --> 00:01:10.150
人間は運転という仕事を 2 つの目と優秀な頭脳 1 つだけでこなします

00:01:10.150 --> 00:01:13.815
実際は片方の目をつぶっていても運転できますね

00:01:13.814 --> 00:01:18.329
確かにできますね  では理由を詳しく見ていきましょう

00:01:18.329 --> 00:01:22.614
なぜ他のセンサーでなくカメラを使用すると自動運転車を作る際に利点があるのか説明します

00:01:22.614 --> 00:01:25.059
レーダーとライダーは実世界を 3D で見ます

00:01:25.060 --> 00:01:28.560
このことは 周りの環境に対する自分の位置を把握するのに大きな利点となります

00:01:28.560 --> 00:01:30.079
カメラは 2D で見ますが

00:01:30.079 --> 00:01:33.719
空間分解能はレーダーとライダーよりはるかに高機能で

00:01:33.719 --> 00:01:37.629
実際にカメラ画像から詳細な情報を推測できます

00:01:37.629 --> 00:01:39.099
ただし 大きな違いは

00:01:39.099 --> 00:01:42.649
コストということになります  カメラのほうがかなり安価です

00:01:42.650 --> 00:01:47.370
そのとおりです  自動運転車はそのうち

00:01:47.370 --> 00:01:52.155
わずかなカメラと実に高性能なアルゴリズムだけを搭載して走行できるようになるでしょう

00:01:52.155 --> 00:01:56.640
そういうわけで コンピュータービジョンをこのモジュールで学ぶのがとても楽しみです

