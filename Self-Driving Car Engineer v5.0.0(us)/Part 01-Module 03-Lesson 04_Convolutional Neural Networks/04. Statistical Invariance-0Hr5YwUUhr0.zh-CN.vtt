WEBVTT
Kind: captions
Language: zh-CN

00:00:00.550 --> 00:00:02.439
这是另一个例子

00:00:02.439 --> 00:00:03.649
你有一张图片

00:00:03.649 --> 00:00:07.179
然后你想让网络鉴别出照片中有一只猫

00:00:07.179 --> 00:00:10.410
猫在图片的哪里并不重要 它仍然是一张有猫的图片

00:00:11.859 --> 00:00:15.000
如果你的网络需要单独学习猫咪位于左上角

00:00:15.000 --> 00:00:17.565
和猫咪位于右下角的情况

00:00:17.565 --> 00:00:20.429
工作量可就大了

00:00:20.429 --> 00:00:24.719
不如你不要明确指定位置 而是告诉它无论在图片的左边

00:00:24.719 --> 00:00:29.000
还是右边 物体和图像都一样

00:00:29.000 --> 00:00:31.216
这就是所谓的平移不变性

00:00:31.216 --> 00:00:34.550
位置不同 但猫咪相同

00:00:34.549 --> 00:00:36.219
还有另一个例子

00:00:36.219 --> 00:00:39.780
假设你有一长段话谈论猫咪

00:00:39.780 --> 00:00:43.280
“猫咪”的意义是否因为其在第一句还是

00:00:43.280 --> 00:00:44.740
第二句而变化？

00:00:45.750 --> 00:00:50.380
大多数时候不会 如果你要用网络训练文本 你会希望

00:00:50.380 --> 00:00:55.140
在每次看到“猫咪”时 网络中学习“猫咪”是什么

00:00:55.140 --> 00:00:58.140
的那部分被重复利用 而不是每次都重新学习

00:00:59.640 --> 00:01:01.829
实现这种网络的方法

00:01:01.829 --> 00:01:03.899
叫做“权重共享”

00:01:03.899 --> 00:01:07.840
当知道两个输入可能包含相同类型的信息时

00:01:07.840 --> 00:01:09.760
你可以共享它们的权重

00:01:09.760 --> 00:01:12.740
并利用这些输入共同训练权重

00:01:12.739 --> 00:01:14.530
这一点非常重要

00:01:14.530 --> 00:01:19.269
统计不变量 即基本上不会随时间或空间改变的事物

00:01:19.269 --> 00:01:20.849
无处不在

00:01:21.859 --> 00:01:23.040
对于图像

00:01:23.040 --> 00:01:27.100
权重共享的思想引出了卷积网络的研究

00:01:27.099 --> 00:01:30.709
对于一般的文本和序列 则涉及嵌入和

00:01:30.709 --> 00:01:31.949
循环神经网络

