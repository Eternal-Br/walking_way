<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Visualizing CNNs
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Convolutional Neural Networks
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. CNNs Have Taken Over.html">
       01. CNNs Have Taken Over
      </a>
     </li>
     <li class="">
      <a href="02. Intro To CNNs.html">
       02. Intro To CNNs
      </a>
     </li>
     <li class="">
      <a href="03. Color.html">
       03. Color
      </a>
     </li>
     <li class="">
      <a href="04. Statistical Invariance.html">
       04. Statistical Invariance
      </a>
     </li>
     <li class="">
      <a href="05. Convolutional Networks.html">
       05. Convolutional Networks
      </a>
     </li>
     <li class="">
      <a href="06. Intuition.html">
       06. Intuition
      </a>
     </li>
     <li class="">
      <a href="07. Filters.html">
       07. Filters
      </a>
     </li>
     <li class="">
      <a href="08. Feature Map Sizes.html">
       08. Feature Map Sizes
      </a>
     </li>
     <li class="">
      <a href="09. Convolutions continued.html">
       09. Convolutions continued
      </a>
     </li>
     <li class="">
      <a href="10. Parameters.html">
       10. Parameters
      </a>
     </li>
     <li class="">
      <a href="11. Quiz Convolution Output Shape.html">
       11. Quiz: Convolution Output Shape
      </a>
     </li>
     <li class="">
      <a href="12. Solution Convolution Output Shape.html">
       12. Solution: Convolution Output Shape
      </a>
     </li>
     <li class="">
      <a href="13. Quiz Number of Parameters.html">
       13. Quiz: Number of Parameters
      </a>
     </li>
     <li class="">
      <a href="14. Solution Number of Parameters.html">
       14. Solution: Number of Parameters
      </a>
     </li>
     <li class="">
      <a href="15. Quiz Parameter Sharing.html">
       15. Quiz: Parameter Sharing
      </a>
     </li>
     <li class="">
      <a href="16. Solution Parameter Sharing.html">
       16. Solution: Parameter Sharing
      </a>
     </li>
     <li class="">
      <a href="17. Visualizing CNNs.html">
       17. Visualizing CNNs
      </a>
     </li>
     <li class="">
      <a href="18. TensorFlow Convolution Layer.html">
       18. TensorFlow Convolution Layer
      </a>
     </li>
     <li class="">
      <a href="19. Explore The Design Space.html">
       19. Explore The Design Space
      </a>
     </li>
     <li class="">
      <a href="20. TensorFlow Max Pooling.html">
       20. TensorFlow Max Pooling
      </a>
     </li>
     <li class="">
      <a href="21. Quiz Pooling Intuition.html">
       21. Quiz: Pooling Intuition
      </a>
     </li>
     <li class="">
      <a href="22. Solution Pooling Intuition.html">
       22. Solution: Pooling Intuition
      </a>
     </li>
     <li class="">
      <a href="23. Quiz Pooling Mechanics.html">
       23. Quiz: Pooling Mechanics
      </a>
     </li>
     <li class="">
      <a href="24. Solution Pooling Mechanics.html">
       24. Solution: Pooling Mechanics
      </a>
     </li>
     <li class="">
      <a href="25. Quiz Pooling Practice.html">
       25. Quiz: Pooling Practice
      </a>
     </li>
     <li class="">
      <a href="26. Solution Pooling Practice.html">
       26. Solution: Pooling Practice
      </a>
     </li>
     <li class="">
      <a href="27. Quiz Average Pooling.html">
       27. Quiz: Average Pooling
      </a>
     </li>
     <li class="">
      <a href="28. Solution Average Pooling.html">
       28. Solution: Average Pooling
      </a>
     </li>
     <li class="">
      <a href="29. 1x1 Convolutions.html">
       29. 1x1 Convolutions
      </a>
     </li>
     <li class="">
      <a href="30. Inception Module.html">
       30. Inception Module
      </a>
     </li>
     <li class="">
      <a href="31. Convolutional Network in TensorFlow.html">
       31. Convolutional Network in TensorFlow
      </a>
     </li>
     <li class="">
      <a href="32. TensorFlow Convolutional Layer Workspaces.html">
       32. TensorFlow Convolutional Layer Workspaces
      </a>
     </li>
     <li class="">
      <a href="33. Solution TensorFlow Convolution Layer.html">
       33. Solution: TensorFlow Convolution Layer
      </a>
     </li>
     <li class="">
      <a href="34. TensorFlow Pooling Layer Workspaces.html">
       34. TensorFlow Pooling Layer Workspaces
      </a>
     </li>
     <li class="">
      <a href="35. Solution TensorFlow Pooling Layer.html">
       35. Solution: TensorFlow Pooling Layer
      </a>
     </li>
     <li class="">
      <a href="36. Lab LeNet in TensorFlow.html">
       36. Lab: LeNet in TensorFlow
      </a>
     </li>
     <li class="">
      <a href="37. LeNet Lab Workspace.html">
       37. LeNet Lab Workspace
      </a>
     </li>
     <li class="">
      <a href="38. CNNs - Additional Resources.html">
       38. CNNs - Additional Resources
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          17. Visualizing CNNs
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h3 id="visualizing-cnns">
          Visualizing CNNs
         </h3>
         <p>
          Let’s look at an example CNN to see how it works in action.
         </p>
         <p>
          The CNN we will look at is trained on ImageNet as described in
          <a href="https://arxiv.org/abs/1311.2901" rel="noopener noreferrer" target="_blank">
           this paper
          </a>
          by Zeiler and Fergus. In the images below (from the same paper), we’ll see
          <em>
           what
          </em>
          each layer in this network detects and see
          <em>
           how
          </em>
          each layer detects more and more complex ideas.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h3 id="layer-1">
          Layer 1
         </h3>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Example patterns that cause activations in the first layer of the network. These range from simple diagonal lines (top left) to green blobs (bottom middle)." class="img img-fluid" src="img/layer-1-grid.png"/>
          <figcaption class="figure-caption">
           <p>
            Example patterns that cause activations in the first layer of the network. These range from simple diagonal lines (top left) to green blobs (bottom middle).
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          The images above are from Matthew Zeiler and Rob Fergus'
          <a href="https://www.youtube.com/watch?v=ghEmQSxT6tw" rel="noopener noreferrer" target="_blank">
           deep visualization toolbox
          </a>
          , which lets us visualize what each layer in a CNN focuses on.
         </p>
         <p>
          Each image in the above grid represents a pattern that causes the neurons in the first layer to activate - in other words, they are patterns that the first layer recognizes. The top left image shows a -45 degree line, while the middle top square shows a +45 degree line. These squares are shown below again for reference.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="As visualized here, the first layer of the CNN can recognize -45 degree lines." class="img img-fluid" src="img/diagonal-line-1.png"/>
          <figcaption class="figure-caption">
           <p>
            As visualized here, the first layer of the CNN can recognize -45 degree lines.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="The first layer of the CNN is also able to recognize +45 degree lines, like the one above." class="img img-fluid" src="img/diagonal-line-2.png"/>
          <figcaption class="figure-caption">
           <p>
            The first layer of the CNN is also able to recognize +45 degree lines, like the one above.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Let's now see some example images that cause such activations. The below grid of images all activated the -45 degree line. Notice how they are all selected despite the fact that they have different colors, gradients, and patterns.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="Example patches that activate the -45 degree line detector in the first layer." class="img img-fluid" src="img/grid-layer-1.png"/>
          <figcaption class="figure-caption">
           <p>
            Example patches that activate the -45 degree line detector in the first layer.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          So, the first layer of our CNN clearly picks out very simple shapes and patterns like lines and blobs.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h3 id="layer-2">
          Layer 2
         </h3>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt='A visualization of the second layer in the CNN. Notice how we are picking up more complex ideas like circles and stripes. The gray grid on the left represents how this layer of the CNN activates (or "what it sees") based on the corresponding images from the grid on the right.' class="img img-fluid" src="img/screen-shot-2016-11-24-at-12.09.02-pm.png"/>
          <figcaption class="figure-caption">
           <p>
            A visualization of the second layer in the CNN. Notice how we are picking up more complex ideas like circles and stripes. The gray grid on the left represents how this layer of the CNN activates (or "what it sees") based on the corresponding images from the grid on the right.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          The second layer of the CNN  captures complex ideas.
         </p>
         <p>
          As you see in the image above, the second layer of the CNN recognizes circles (second row, second column), stripes (first row, second column), and rectangles (bottom right).
         </p>
         <p>
          <strong>
           The CNN learns to do this on its own.
          </strong>
          There is no special instruction for the CNN to focus on more complex objects in deeper layers. That's just how it normally works out when you feed training data into a CNN.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h3 id="layer-3">
          Layer 3
         </h3>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt='A visualization of the third layer in the CNN. The gray grid on the left represents how this layer of the CNN activates (or "what it sees") based on the corresponding images from the grid on the right.' class="img img-fluid" src="img/screen-shot-2016-11-24-at-12.09.24-pm.png"/>
          <figcaption class="figure-caption">
           <p>
            A visualization of the third layer in the CNN. The gray grid on the left represents how this layer of the CNN activates (or "what it sees") based on the corresponding images from the grid on the right.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          The third layer picks out complex combinations of features from the second layer. These include things like grids, and honeycombs (top left), wheels (second row, second column), and even faces (third row, third column).
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          We'll skip layer 4, which continues this progression, and jump right to the fifth and final layer of this CNN.
         </p>
         <h3 id="layer-5">
          Layer 5
         </h3>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt='A visualization of the fifth and final layer of the CNN. The gray grid on the left represents how this layer of the CNN activates (or "what it sees") based on the corresponding images from the grid on the right.' class="img img-fluid" src="img/screen-shot-2016-11-24-at-12.08.11-pm.png"/>
          <figcaption class="figure-caption">
           <p>
            A visualization of the fifth and final layer of the CNN. The gray grid on the left represents how this layer of the CNN activates (or "what it sees") based on the corresponding images from the grid on the right.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          The last layer picks out the highest order ideas that we care about for classification, like dog faces, bird faces, and bicycles.
         </p>
         <h3 id="on-to-tensorflow">
          On to TensorFlow
         </h3>
         <p>
          This concludes our high-level discussion of Convolutional Neural Networks.
         </p>
         <p>
          Next you'll practice actually building these networks in TensorFlow.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="18. TensorFlow Convolution Layer.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('17. Visualizing CNNs')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
