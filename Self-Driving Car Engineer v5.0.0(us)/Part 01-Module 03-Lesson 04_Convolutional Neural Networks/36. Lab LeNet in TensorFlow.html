<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Lab: LeNet in TensorFlow
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Convolutional Neural Networks
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. CNNs Have Taken Over.html">
       01. CNNs Have Taken Over
      </a>
     </li>
     <li class="">
      <a href="02. Intro To CNNs.html">
       02. Intro To CNNs
      </a>
     </li>
     <li class="">
      <a href="03. Color.html">
       03. Color
      </a>
     </li>
     <li class="">
      <a href="04. Statistical Invariance.html">
       04. Statistical Invariance
      </a>
     </li>
     <li class="">
      <a href="05. Convolutional Networks.html">
       05. Convolutional Networks
      </a>
     </li>
     <li class="">
      <a href="06. Intuition.html">
       06. Intuition
      </a>
     </li>
     <li class="">
      <a href="07. Filters.html">
       07. Filters
      </a>
     </li>
     <li class="">
      <a href="08. Feature Map Sizes.html">
       08. Feature Map Sizes
      </a>
     </li>
     <li class="">
      <a href="09. Convolutions continued.html">
       09. Convolutions continued
      </a>
     </li>
     <li class="">
      <a href="10. Parameters.html">
       10. Parameters
      </a>
     </li>
     <li class="">
      <a href="11. Quiz Convolution Output Shape.html">
       11. Quiz: Convolution Output Shape
      </a>
     </li>
     <li class="">
      <a href="12. Solution Convolution Output Shape.html">
       12. Solution: Convolution Output Shape
      </a>
     </li>
     <li class="">
      <a href="13. Quiz Number of Parameters.html">
       13. Quiz: Number of Parameters
      </a>
     </li>
     <li class="">
      <a href="14. Solution Number of Parameters.html">
       14. Solution: Number of Parameters
      </a>
     </li>
     <li class="">
      <a href="15. Quiz Parameter Sharing.html">
       15. Quiz: Parameter Sharing
      </a>
     </li>
     <li class="">
      <a href="16. Solution Parameter Sharing.html">
       16. Solution: Parameter Sharing
      </a>
     </li>
     <li class="">
      <a href="17. Visualizing CNNs.html">
       17. Visualizing CNNs
      </a>
     </li>
     <li class="">
      <a href="18. TensorFlow Convolution Layer.html">
       18. TensorFlow Convolution Layer
      </a>
     </li>
     <li class="">
      <a href="19. Explore The Design Space.html">
       19. Explore The Design Space
      </a>
     </li>
     <li class="">
      <a href="20. TensorFlow Max Pooling.html">
       20. TensorFlow Max Pooling
      </a>
     </li>
     <li class="">
      <a href="21. Quiz Pooling Intuition.html">
       21. Quiz: Pooling Intuition
      </a>
     </li>
     <li class="">
      <a href="22. Solution Pooling Intuition.html">
       22. Solution: Pooling Intuition
      </a>
     </li>
     <li class="">
      <a href="23. Quiz Pooling Mechanics.html">
       23. Quiz: Pooling Mechanics
      </a>
     </li>
     <li class="">
      <a href="24. Solution Pooling Mechanics.html">
       24. Solution: Pooling Mechanics
      </a>
     </li>
     <li class="">
      <a href="25. Quiz Pooling Practice.html">
       25. Quiz: Pooling Practice
      </a>
     </li>
     <li class="">
      <a href="26. Solution Pooling Practice.html">
       26. Solution: Pooling Practice
      </a>
     </li>
     <li class="">
      <a href="27. Quiz Average Pooling.html">
       27. Quiz: Average Pooling
      </a>
     </li>
     <li class="">
      <a href="28. Solution Average Pooling.html">
       28. Solution: Average Pooling
      </a>
     </li>
     <li class="">
      <a href="29. 1x1 Convolutions.html">
       29. 1x1 Convolutions
      </a>
     </li>
     <li class="">
      <a href="30. Inception Module.html">
       30. Inception Module
      </a>
     </li>
     <li class="">
      <a href="31. Convolutional Network in TensorFlow.html">
       31. Convolutional Network in TensorFlow
      </a>
     </li>
     <li class="">
      <a href="32. TensorFlow Convolutional Layer Workspaces.html">
       32. TensorFlow Convolutional Layer Workspaces
      </a>
     </li>
     <li class="">
      <a href="33. Solution TensorFlow Convolution Layer.html">
       33. Solution: TensorFlow Convolution Layer
      </a>
     </li>
     <li class="">
      <a href="34. TensorFlow Pooling Layer Workspaces.html">
       34. TensorFlow Pooling Layer Workspaces
      </a>
     </li>
     <li class="">
      <a href="35. Solution TensorFlow Pooling Layer.html">
       35. Solution: TensorFlow Pooling Layer
      </a>
     </li>
     <li class="">
      <a href="36. Lab LeNet in TensorFlow.html">
       36. Lab: LeNet in TensorFlow
      </a>
     </li>
     <li class="">
      <a href="37. LeNet Lab Workspace.html">
       37. LeNet Lab Workspace
      </a>
     </li>
     <li class="">
      <a href="38. CNNs - Additional Resources.html">
       38. CNNs - Additional Resources
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          36. Lab: LeNet in TensorFlow
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="LeNet. Source: Yann Lecun." class="img img-fluid" src="img/screenshot-2016-11-26-17.52.14.png"/>
          <figcaption class="figure-caption">
           <p>
            LeNet. Source: Yann Lecun.
           </p>
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          You're now going to put together everything you've learned and implement the
          <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98.pdf" rel="noopener noreferrer" target="_blank">
           LeNet
          </a>
          architecture using TensorFlow.
         </p>
         <p>
          When you get to your next project, remember that LeNet can be a great starting point for your network architecture!
         </p>
         <h3 id="instructions">
          Instructions:
         </h3>
         <ol>
          <li>
           Go to the LeNet with GPU workspace
          </li>
          <li>
           Open the jupyter notebook
           <code>
            LeNet-Lab.ipynb
           </code>
          </li>
          <li>
           Finish off the architecture implementation in the
           <code>
            LeNet
           </code>
           function. That's the only piece that's missing.
          </li>
         </ol>
         <p>
          **Important: **  Remember to
          <strong>
           turn off
          </strong>
          your GPU when not training.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h3 id="preprocessing">
          Preprocessing
         </h3>
         <p>
          An MNIST image is initially 784 features (1D). If the data is not normalized from [0, 255] to [0, 1], normalize it. We reshape this to
          <code>
           (28, 28, 1)
          </code>
          (3D), and pad the image with 0s such that the height and width are 32 (centers digit further). Thus, the input shape going into the first convolutional layer is
          <code>
           32x32x1
          </code>
          .
         </p>
         <h3 id="specs">
          Specs
         </h3>
         <p>
          <strong>
           Convolution layer 1
          </strong>
          . The output shape should be
          <code>
           28x28x6
          </code>
          .
         </p>
         <p>
          <strong>
           Activation 1
          </strong>
          . Your choice of activation function.
         </p>
         <p>
          <strong>
           Pooling layer 1
          </strong>
          . The output shape should be
          <code>
           14x14x6
          </code>
          .
         </p>
         <p>
          <strong>
           Convolution layer 2
          </strong>
          . The output shape should be
          <code>
           10x10x16
          </code>
          .
         </p>
         <p>
          <strong>
           Activation 2
          </strong>
          . Your choice of activation function.
         </p>
         <p>
          <strong>
           Pooling layer 2
          </strong>
          . The output shape should be
          <code>
           5x5x16
          </code>
          .
         </p>
         <p>
          <strong>
           Flatten layer
          </strong>
          . Flatten the output shape of the final pooling layer such that it's 1D instead of 3D. The easiest way to do is by using
          <code>
           tf.contrib.layers.flatten
          </code>
          , which is already imported for you.
         </p>
         <p>
          <strong>
           Fully connected layer 1
          </strong>
          . This should have
          <strong>
           120 outputs
          </strong>
          .
         </p>
         <p>
          <strong>
           Activation 3
          </strong>
          . Your choice of activation function.
         </p>
         <p>
          <strong>
           Fully connected layer 2
          </strong>
          . This should have
          <strong>
           84 outputs
          </strong>
          .
         </p>
         <p>
          <strong>
           Activation 4
          </strong>
          . Your choice of activation function.
         </p>
         <p>
          <strong>
           Fully connected layer 3
          </strong>
          . This should have
          <strong>
           10 outputs
          </strong>
          .
         </p>
         <p>
          You'll return the result of the final fully connected layer from the
          <code>
           LeNet
          </code>
          function.
         </p>
         <p>
          If implemented correctly you should see output similar to the following:
         </p>
         <pre><code class="sh language-sh">EPOCH 1 ...
Validation loss = 52.809
Validation accuracy = 0.864

EPOCH 2 ...
Validation loss = 24.749
Validation accuracy = 0.915

EPOCH 3 ...
Validation loss = 17.719
Validation accuracy = 0.930

EPOCH 4 ...
Validation loss = 12.188
Validation accuracy = 0.943

EPOCH 5 ...
Validation loss = 8.935
Validation accuracy = 0.954

EPOCH 6 ...
Validation loss = 7.674
Validation accuracy = 0.956

EPOCH 7 ...
Validation loss = 6.822
Validation accuracy = 0.956

EPOCH 8 ...
Validation loss = 5.451
Validation accuracy = 0.961

EPOCH 9 ...
Validation loss = 4.881
Validation accuracy = 0.964

EPOCH 10 ...
Validation loss = 4.623
Validation accuracy = 0.964

Test loss = 4.726
Test accuracy = 0.962</code></pre>
         <h3 id="parameters-galore">
          Parameters Galore
         </h3>
         <p>
          As an additional fun exercise calculate the total number of parameters used by the network. Note, the convolutional layers use weight sharing!
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="37. LeNet Lab Workspace.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('36. Lab: LeNet in TensorFlow')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
