WEBVTT
Kind: captions
Language: ja-JP

00:00:00.000 --> 00:00:02.819
&gt;&gt; 皆さんが考えているとおり GPUはグラフィックを多用する

00:00:02.819 --> 00:00:06.025
ビデオゲームをレンダリングするために構築されたデバイスです

00:00:06.025 --> 00:00:09.750
しかしGPUはディープラーニングにおいても非常に重要です

00:00:09.750 --> 00:00:13.574
GPUはハイスループット計算に合わせて最適化されます

00:00:13.574 --> 00:00:16.589
CPUは主にレイテンシーに合わせて最適化され

00:00:16.589 --> 00:00:20.199
 一連の命令をできるだけ速く実行しますが

00:00:20.199 --> 00:00:22.244
GPUはスループットに合わせて最適化され

00:00:22.245 --> 00:00:25.425
できるだけ多くの同時計算を実行します

00:00:25.425 --> 00:00:28.410
コンピューターグラフィックスでは 画面上の多数のピクセルを同時に更新する必要があるため

00:00:28.410 --> 00:00:31.605
スループット計算が重要です

00:00:31.605 --> 00:00:34.530
また ディープラーニングの基本となる計算には

00:00:34.530 --> 00:00:36.570
多くの並列処理が含まれるため

00:00:36.570 --> 00:00:39.359
ディープラーニングにおいてもスループット計算は重要です

00:00:39.359 --> 00:00:42.359
&gt;&gt; CPUでのネットワークのトレーニングからGPUへ移行すると

00:00:42.359 --> 00:00:45.969
通常どの程度の加速が見られるでしょうか?

00:00:45.969 --> 00:00:47.504
&gt;&gt; 実行しているソフトウェアの設計方法や

00:00:47.505 --> 00:00:50.445
比較しているCPUとGPUなど

00:00:50.445 --> 00:00:53.605
さまざまな要因によって異なります

00:00:53.604 --> 00:00:56.339
たとえば ノートPCの低消費電力のプロセッサーは

00:00:56.340 --> 00:00:59.440
大型のサーバーのプロセッサーよりはるかに低速です

00:00:59.439 --> 00:01:01.769
しかし経験則では ネットワークはCPUよりGPUの方が

00:01:01.770 --> 00:01:04.760
約5倍速くトレーニングされます

00:01:04.760 --> 00:01:06.495
&gt;&gt; 私も似たような経験があります

00:01:06.495 --> 00:01:10.890
経験上 ネットワークのトレーニング速度が5倍から10倍に上がれば

00:01:10.890 --> 00:01:15.200
はるかに短い時間で簡単に進歩させることができます

00:01:15.200 --> 00:01:17.459
時間に余裕ができれば 新しいアプローチを試したり

00:01:17.459 --> 00:01:21.000
機能についてのフィードバックを より早く入手したりすることができます

00:01:21.000 --> 00:01:24.674
迅速なフィードバックを得るためには

00:01:24.674 --> 00:01:26.819
さらに 毎回ゼロから始めるのではなく

00:01:26.819 --> 00:01:30.000
転移学習を使って トレーニング済みのネットワークを活用することをお勧めします

