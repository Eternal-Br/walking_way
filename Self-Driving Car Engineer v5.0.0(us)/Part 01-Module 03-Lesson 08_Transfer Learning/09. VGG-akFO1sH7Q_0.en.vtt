WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.970
&gt;&gt; In 2014, two different groups nearly tied in

00:00:03.970 --> 00:00:07.870
the ImageNet competition with the seven percent classification error.

00:00:07.870 --> 00:00:10.734
One of those networks is called VGGNet,

00:00:10.734 --> 00:00:12.804
or sometimes just VGG,

00:00:12.804 --> 00:00:16.600
and it came from the Visual Geometry Group at Oxford University.

00:00:16.600 --> 00:00:20.705
&gt;&gt; VGG has a simple and elegant architecture,

00:00:20.704 --> 00:00:22.849
which makes it great for transfer learning.

00:00:22.850 --> 00:00:27.260
The VGG architecture is just a long sequence of three-by-three convolutions,

00:00:27.260 --> 00:00:29.405
broken up by two-by-two pooling layers,

00:00:29.405 --> 00:00:33.000
and finished by a trio of fully-connected layers at the end.

00:00:33.000 --> 00:00:35.170
Lots of engineers use VGG as

00:00:35.170 --> 00:00:38.435
a starting point for working on other image classification tasks,

00:00:38.435 --> 00:00:40.219
and it works really well.

00:00:40.219 --> 00:00:43.390
The flexibility of VGG is one of its great strengths.

