WEBVTT
Kind: captions
Language: en

00:00:00.380 --> 00:00:05.229
The simplest feature you can get from images consists of raw color values.

00:00:05.230 --> 00:00:08.100
For instance, here is an image of a car.

00:00:08.099 --> 00:00:12.949
Let's say you want to find out whether some region of a new test image

00:00:12.949 --> 00:00:14.829
contains a car or not.

00:00:14.830 --> 00:00:16.230
What do you do?

00:00:16.230 --> 00:00:22.089
Well, using your known car image as is, you can simply find the image difference

00:00:22.089 --> 00:00:27.939
between the car image and the test region, and see the difference is small.

00:00:27.940 --> 00:00:31.440
This basically means subtracting the corresponding color values,

00:00:31.440 --> 00:00:35.719
aggregating the differences and comparing it with the threshold.

00:00:35.719 --> 00:00:39.500
Alternatively, you could compute the correlation between the car image and

00:00:39.500 --> 00:00:42.520
test region and check if that is high.

00:00:42.520 --> 00:00:46.359
Either way, this general approach is known as template matching.

00:00:46.359 --> 00:00:47.839
Your known image is the template or

00:00:47.840 --> 00:00:51.900
model and you try to match it with regions of the test image.

00:00:51.899 --> 00:00:56.390
Template matching does work in limited circumstances but isn't very helpful for

00:00:56.390 --> 00:00:57.450
our case.

00:00:57.450 --> 00:00:58.170
Can you guess why?

