WEBVTT
Kind: captions
Language: zh-CN

00:00:00.410 --> 00:00:02.710
无论你是直接应用原始颜色还是

00:00:02.710 --> 00:00:06.599
通过它们的直方图 你仍然不能解决

00:00:06.599 --> 00:00:10.890
物体种类相同 但颜色不同的问题

00:00:10.890 --> 00:00:14.585
也就是说 依然无法识别同种物体在颜色上的差异

00:00:14.585 --> 00:00:16.625
以这个图像为例

00:00:16.625 --> 00:00:21.184
这个图像的颜色值在 RGB 颜色空间是这样分布的

00:00:21.184 --> 00:00:26.914
我们将红色、绿色和蓝色强度作为三个坐标轴

00:00:26.914 --> 00:00:28.644
本例中 红色和

00:00:28.644 --> 00:00:32.594
蓝色汽车的像素聚集成两个较为独立的组

00:00:32.594 --> 00:00:35.844
虽然我们可以想办法

00:00:35.844 --> 00:00:37.350
通过 RGB 值区分不同组

00:00:37.350 --> 00:00:41.365
然而 当引入更多颜色时 问题马上就变得复杂得多

00:00:41.365 --> 00:00:43.920
那么 从这些颜色值中

00:00:43.920 --> 00:00:48.454
我们能否获得汽车共有的属性 并利用这些属性

00:00:48.454 --> 00:00:51.539
将汽车与图像的其他内容进行区分？

00:00:51.539 --> 00:00:56.060
在车道线定位那节课 我们探索了 HLS、LUV 等其他色彩空间

00:00:56.060 --> 00:00:59.990
来探讨其他颜色表示方式能否

00:00:59.990 --> 00:01:03.910
将你正在寻找的目标与背景区分开来

00:01:03.909 --> 00:01:06.979
我的个人感觉是 汽车颜色的饱和度更高

00:01:06.980 --> 00:01:08.859
而一般而言 背景饱和度较低 看上去更苍白一些

00:01:10.060 --> 00:01:13.570
或许你应该查看饱和值 而不是从摄像头获得的

00:01:13.569 --> 00:01:16.329
原始红、绿、蓝色值

00:01:16.329 --> 00:01:20.010
或者其他色彩变换 比如 HSV

00:01:20.010 --> 00:01:22.490
或者 LUV 是不是会更有效？

00:01:22.489 --> 00:01:26.549
我对 HSV 空间内的像素分布比较好奇

00:01:26.549 --> 00:01:27.390
啊哈！

00:01:27.390 --> 00:01:28.579
对于这张图像

00:01:28.579 --> 00:01:33.329
汽车的像素似乎都在这一饱和度值的平面上

00:01:33.329 --> 00:01:34.829
这就比较说得通了

00:01:34.829 --> 00:01:36.649
无论汽车的颜色或色相怎样

00:01:36.650 --> 00:01:41.210
在饱和度域内 汽车的外观往往会更加突出

00:01:41.209 --> 00:01:43.919
不过这不一定适用于所有图像

00:01:43.920 --> 00:01:48.099
你需要做的是 取一批不同的图像

00:01:48.099 --> 00:01:52.750
并研究它们的像素值在各种色彩空间内的分布方式

00:01:52.750 --> 00:01:56.930
然后 你需要验证 在该色彩空间内的某些维度中

00:01:56.930 --> 00:02:00.100
汽车是否能与其他物体区分开来

00:02:00.099 --> 00:02:02.009
你可以多尝试一些不同的色彩空间

00:02:02.010 --> 00:02:04.770
看看哪个空间能提供最有用的特征

