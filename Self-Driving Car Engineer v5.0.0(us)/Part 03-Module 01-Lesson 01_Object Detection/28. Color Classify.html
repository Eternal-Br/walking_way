<!-- udacimak v1.4.4 -->
<!DOCTYPE html>
<html lang="en">
 <head>
  <meta charset="utf-8"/>
  <meta content="width=device-width, initial-scale=1.0" name="viewport"/>
  <meta content="ie=edge" http-equiv="X-UA-Compatible"/>
  <title>
   Color Classify
  </title>
  <link href="../assets/css/bootstrap.min.css" rel="stylesheet"/>
  <link href="../assets/css/plyr.css" rel="stylesheet"/>
  <link href="../assets/css/katex.min.css" rel="stylesheet"/>
  <link href="../assets/css/jquery.mCustomScrollbar.min.css" rel="stylesheet"/>
  <link href="../assets/css/styles.css" rel="stylesheet"/>
  <link href="../assets/img/udacimak.png" rel="shortcut icon" type="image/png">
  </link>
 </head>
 <body>
  <div class="wrapper">
   <nav id="sidebar">
    <div class="sidebar-header">
     <h3>
      Object Detection
     </h3>
    </div>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled components">
     <li class="">
      <a href="01. Intro to Vehicle Tracking.html">
       01. Intro to Vehicle Tracking
      </a>
     </li>
     <li class="">
      <a href="02. Arpan and Drew.html">
       02. Arpan and Drew
      </a>
     </li>
     <li class="">
      <a href="03. Finding Cars.html">
       03. Finding Cars
      </a>
     </li>
     <li class="">
      <a href="04. Object Detection Overview.html">
       04. Object Detection Overview
      </a>
     </li>
     <li class="">
      <a href="05. Manual Vehicle Detection.html">
       05. Manual Vehicle Detection
      </a>
     </li>
     <li class="">
      <a href="06. Features.html">
       06. Features
      </a>
     </li>
     <li class="">
      <a href="07. Feature Intuition.html">
       07. Feature Intuition
      </a>
     </li>
     <li class="">
      <a href="08. Color Features.html">
       08. Color Features
      </a>
     </li>
     <li class="">
      <a href="09. Template Matching.html">
       09. Template Matching
      </a>
     </li>
     <li class="">
      <a href="10. Template Matching Quiz.html">
       10. Template Matching Quiz
      </a>
     </li>
     <li class="">
      <a href="11. Color Histogram Features.html">
       11. Color Histogram Features
      </a>
     </li>
     <li class="">
      <a href="12. Histograms of Color.html">
       12. Histograms of Color
      </a>
     </li>
     <li class="">
      <a href="13. Histogram Comparison.html">
       13. Histogram Comparison
      </a>
     </li>
     <li class="">
      <a href="14. Color Spaces.html">
       14. Color Spaces
      </a>
     </li>
     <li class="">
      <a href="15. Explore Color Spaces.html">
       15. Explore Color Spaces
      </a>
     </li>
     <li class="">
      <a href="16. Spatial Binning of Color.html">
       16. Spatial Binning of Color
      </a>
     </li>
     <li class="">
      <a href="17. Gradient Features.html">
       17. Gradient Features
      </a>
     </li>
     <li class="">
      <a href="18. HOG Features.html">
       18. HOG Features
      </a>
     </li>
     <li class="">
      <a href="19. Data Exploration.html">
       19. Data Exploration
      </a>
     </li>
     <li class="">
      <a href="20. scikit-image HOG.html">
       20. scikit-image HOG
      </a>
     </li>
     <li class="">
      <a href="21. Combining Features.html">
       21. Combining Features
      </a>
     </li>
     <li class="">
      <a href="22. Combine and Normalize Features.html">
       22. Combine and Normalize Features
      </a>
     </li>
     <li class="">
      <a href="23. Build a Classifier.html">
       23. Build a Classifier
      </a>
     </li>
     <li class="">
      <a href="24. Labeled Data.html">
       24. Labeled Data
      </a>
     </li>
     <li class="">
      <a href="25. Data Preparation.html">
       25. Data Preparation
      </a>
     </li>
     <li class="">
      <a href="26. Train a Classifier.html">
       26. Train a Classifier
      </a>
     </li>
     <li class="">
      <a href="27. Parameter Tuning.html">
       27. Parameter Tuning
      </a>
     </li>
     <li class="">
      <a href="28. Color Classify.html">
       28. Color Classify
      </a>
     </li>
     <li class="">
      <a href="29. HOG Classify.html">
       29. HOG Classify
      </a>
     </li>
     <li class="">
      <a href="30. Sliding Windows.html">
       30. Sliding Windows
      </a>
     </li>
     <li class="">
      <a href="31. How many windows.html">
       31. How many windows?
      </a>
     </li>
     <li class="">
      <a href="32. Sliding Window Implementation.html">
       32. Sliding Window Implementation
      </a>
     </li>
     <li class="">
      <a href="33. Multi-scale Windows.html">
       33. Multi-scale Windows
      </a>
     </li>
     <li class="">
      <a href="34. Search and Classify.html">
       34. Search and Classify
      </a>
     </li>
     <li class="">
      <a href="35. Hog Sub-sampling Window Search.html">
       35. Hog Sub-sampling Window Search
      </a>
     </li>
     <li class="">
      <a href="36. False Positives.html">
       36. False Positives
      </a>
     </li>
     <li class="">
      <a href="37. Multiple Detections &amp; False Positives.html">
       37. Multiple Detections &amp; False Positives
      </a>
     </li>
     <li class="">
      <a href="38. Tracking Pipeline.html">
       38. Tracking Pipeline
      </a>
     </li>
     <li class="">
      <a href="39. Summary.html">
       39. Summary
      </a>
     </li>
     <li class="">
      <a href="40. Traditional vs. Deep Learning Approach.html">
       40. Traditional vs. Deep Learning Approach
      </a>
     </li>
    </ul>
    <ul class="sidebar-list list-unstyled CTAs">
     <li>
      <a class="article" href="../index.html">
       Back to Home
      </a>
     </li>
    </ul>
   </nav>
   <div id="content">
    <header class="container-fluild header">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <div class="align-items-middle">
         <button class="btn btn-toggle-sidebar" id="sidebarCollapse" type="button">
          <div>
          </div>
          <div>
          </div>
          <div>
          </div>
         </button>
         <h1 style="display: inline-block">
          28. Color Classify
         </h1>
        </div>
       </div>
      </div>
     </div>
    </header>
    <main class="container">
     <div class="row">
      <div class="col-12">
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h1 id="color-classify">
          Color Classify
         </h1>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <figure class="figure">
          <img alt="" class="img img-fluid" src="img/car-color-and-hist.jpg"/>
          <figcaption class="figure-caption">
          </figcaption>
         </figure>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <p>
          Now we'll try training a classifier on our dataset.  First, we'll see how well it does just using spatially binned color and color histograms.
         </p>
         <p>
          To do this, we'll use the functions you defined in previous exercises, namely,
          <code>
           bin_spatial()
          </code>
          ,
          <code>
           color_hist()
          </code>
          , and
          <code>
           extract_features()
          </code>
          .  We'll then read in our car and non-car images, and extract the color features for each.
         </p>
         <p>
          All that remains is to define a labels vector, shuffle and split the data into training and testing sets, scale the feature vectors to zero mean and unit variance, and finally, define a classifier and train it!
         </p>
         <p>
          Our labels vector
          <code>
           y
          </code>
          in this case will just be a binary vector indicating whether each feature vector in our dataset corresponds to a car or non-car (1's for cars, 0's for non-cars).  Given lists of car and non-car features (the output of
          <code>
           extract_features()
          </code>
          ) we can define a labels vector like this:
         </p>
         <pre><code class="python language-python">import numpy as np
# Define a labels vector based on features lists
y = np.hstack((np.ones(len(car_features)), 
              np.zeros(len(notcar_features))))</code></pre>
         <p>
          Next, we'll stack our feature vectors like before:
         </p>
         <pre><code class="python language-python"># Create an array stack of feature vectors
X = np.vstack((car_features, notcar_features)).astype(np.float64)</code></pre>
         <p>
          And now we're ready to shuffle and split the data into training and testing sets.  To do this we'll use the Scikit-Learn
          <code>
           train_test_split()
          </code>
          function, but it's worth noting that recently, this function moved from the
          <code>
           sklearn.cross_validation
          </code>
          package (in
          <code>
           sklearn
          </code>
          version &lt;=0.17) to the
          <code>
           sklearn.model_selection
          </code>
          package  (in
          <code>
           sklearn
          </code>
          version &gt;=0.18).
         </p>
         <p>
          In the quiz editor we're still running
          <code>
           sklearn
          </code>
          v0.17, so we'll import it like this:
         </p>
         <pre><code class="python language-python">from sklearn.cross_validation import train_test_split
# But, if you are using scikit-learn &gt;= 0.18 then use this:
# from sklearn.model_selection import train_test_split</code></pre>
         <p>
          <code>
           train_test_split()
          </code>
          performs both the shuffle and split of the data and you'll call it like this (here choosing to initialize the shuffle with a different random state each time):
         </p>
         <pre><code class="python language-python"># Split up data into randomized training and test sets
rand_state = np.random.randint(0, 100)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=rand_state)</code></pre>
         <p>
          Now that we have split into training and test sets, we can scale our features. It's important to do the scaling after splitting the data, otherwise you are allowing the scaler to peer into your test data!
         </p>
         <pre><code class="python language-python">from sklearn.preprocessing import StandardScaler
# Fit a per-column scaler only on the training data
X_scaler = StandardScaler().fit(X_train)
# Apply the scaler to both X_train and X_test
scaled_X_train = X_scaler.transform(X_train)
scaled_X_test = X_scaler.transform(X_test)</code></pre>
         <h2 id="-warning-when-dealing-with-image-data-that-was-extracted-from-video-you-may-be-dealing-with-sequences-of-images-where-your-target-object-vehicles-in-this-case-appear-almost-identical-in-a-whole-series-of-images--in-such-a-case-even-a-randomized-train-test-split-will-be-subject-to-overfitting-because-images-in-the-training-set-may-be-nearly-identical-to-images-in-the-test-set--for-the-subset-of-images-used-in-the-next-several-quizzes-this-is-not-a-problem-but-to-optimize-your-classifier-for-the-project-you-may-need-to-worry-about-time-series-of-images">
          #### Warning: when dealing with image data that was extracted from video, you may be dealing with sequences of images where your target object (vehicles in this case) appear almost identical in a whole series of images.  In such a case, even a randomized train-test split will be subject to overfitting because images in the training set may be nearly identical to images in the test set.  For the subset of images used in the next several quizzes, this is not a problem, but to optimize your classifier for the project, you may need to worry about time-series of images!
         </h2>
         <p>
          Now, you're ready to define and train a classifier!  Here we'll try a Linear Support Vector Machine.  To define and train your classifier it takes just a few lines of code:
         </p>
         <pre><code class="python language-python">from sklearn.svm import LinearSVC
# Use a linear SVC (support vector classifier)
svc = LinearSVC()
# Train the SVC
svc.fit(scaled_X_train, y_train)</code></pre>
         <p>
          Then you can check the accuracy of your classifier on the test dataset like this:
         </p>
         <pre><code class="python language-python">print('Test Accuracy of SVC = ', svc.score(scaled_X_test, y_test))</code></pre>
         <p>
          Or you can make predictions on a subset of the test data and compare directly with ground truth:
         </p>
         <pre><code class="python language-python">print('My SVC predicts: ', svc.predict(scaled_X_test[0:10].reshape(1, -1)))
print('For labels: ', y_test[0:10])</code></pre>
         <p>
          Play with the parameter values
          <code>
           spatial
          </code>
          and
          <code>
           histbin
          </code>
          in the exercise below to see how the classifier accuracy and training time vary with the feature vector input.
         </p>
        </div>
       </div>
       <div class="divider">
       </div>
       <div class="ud-atom">
        <h3>
        </h3>
        <div>
         <h4>
          Start Quiz:
         </h4>
         <div>
          <div class="nav nav-tabs nav-fill" id="question-tabs" role="tablist">
           <a aria-controls="229502-car_features-py" aria-selected="true" class="nav-item nav-link active show" data-toggle="tab" href="#229502-car_features-py" id="tab-229502-car_features-py" role="tab">
            car_features.py
           </a>
          </div>
          <div class="tab-content" id="question-tab-contents" style="padding: 20px 0;">
           <div aria-labelledby="tab-229502-car_features-py" class="tab-pane active show" id="229502-car_features-py" role="tabpanel">
            <pre><code></code>import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import numpy as np
import cv2
import glob
import time
from sklearn.svm import LinearSVC
from sklearn.preprocessing import StandardScaler
# NOTE: the next import is only valid 
# for scikit-learn version &lt;= 0.17
# if you are using scikit-learn &gt;= 0.18 then use this:
# from sklearn.model_selection import train_test_split
from sklearn.cross_validation import train_test_split

# Define a function to compute binned color features  
def bin_spatial(img, size=(32, 32)):
    # Use cv2.resize().ravel() to create the feature vector
    features = cv2.resize(img, size).ravel() 
    # Return the feature vector
    return features

# Define a function to compute color histogram features  
def color_hist(img, nbins=32, bins_range=(0, 256)):
    # Compute the histogram of the color channels separately
    channel1_hist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)
    channel2_hist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)
    channel3_hist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)
    # Concatenate the histograms into a single feature vector
    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))
    # Return the individual histograms, bin_centers and feature vector
    return hist_features

# Define a function to extract features from a list of images
# Have this function call bin_spatial() and color_hist()
def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),
                        hist_bins=32, hist_range=(0, 256)):
    # Create a list to append feature vectors to
    features = []
    # Iterate through the list of images
    for file in imgs:
        # Read in each one by one
        image = mpimg.imread(file)
        # apply color conversion if other than 'RGB'
        if cspace != 'RGB':
            if cspace == 'HSV':
                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
            elif cspace == 'LUV':
                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)
            elif cspace == 'HLS':
                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)
            elif cspace == 'YUV':
                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)
        else: feature_image = np.copy(image)      
        # Apply bin_spatial() to get spatial color features
        spatial_features = bin_spatial(feature_image, size=spatial_size)
        # Apply color_hist() also with a color space option now
        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)
        # Append the new feature vector to the features list
        features.append(np.concatenate((spatial_features, hist_features)))
    # Return list of feature vectors
    return features


# Read in car and non-car images
images = glob.glob('*.jpeg')
cars = []
notcars = []
for image in images:
    if 'image' in image or 'extra' in image:
        notcars.append(image)
    else:
        cars.append(image)

# TODO play with these values to see how your classifier
# performs under different binning scenarios
spatial = 32
histbin = 32

car_features = extract_features(cars, cspace='RGB', spatial_size=(spatial, spatial),
                        hist_bins=histbin, hist_range=(0, 256))
notcar_features = extract_features(notcars, cspace='RGB', spatial_size=(spatial, spatial),
                        hist_bins=histbin, hist_range=(0, 256))

# Create an array stack of feature vectors
X = np.vstack((car_features, notcar_features)).astype(np.float64)

# Define the labels vector
y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))

# Split up data into randomized training and test sets
rand_state = np.random.randint(0, 100)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=rand_state)
    
# Fit a per-column scaler only on the training data
X_scaler = StandardScaler().fit(X_train)
# Apply the scaler to X_train and X_test
X_train = X_scaler.transform(X_train)
X_test = X_scaler.transform(X_test)

print('Using spatial binning of:',spatial,
    'and', histbin,'histogram bins')
print('Feature vector length:', len(X_train[0]))
# Use a linear SVC 
svc = LinearSVC()
# Check the training time for the SVC
t=time.time()
svc.fit(X_train, y_train)
t2 = time.time()
print(round(t2-t, 2), 'Seconds to train SVC...')
# Check the score of the SVC
print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))
# Check the prediction time for a single sample
t=time.time()
n_predict = 10
print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))
print('For these',n_predict, 'labels: ', y_test[0:n_predict])
t2 = time.time()
print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')</pre>
           </div>
          </div>
         </div>
        </div>
       </div>
       <div class="divider">
       </div>
      </div>
      <div class="col-12">
       <p class="text-right">
        <a class="btn btn-outline-primary mt-4" href="29. HOG Classify.html" role="button">
         Next Concept
        </a>
       </p>
      </div>
     </div>
    </main>
    <footer class="footer">
     <div class="container">
      <div class="row">
       <div class="col-12">
        <p class="text-center">
         udacity2.0 If you need the newest courses Plase add me wechat: udacity6
        </p>
       </div>
      </div>
     </div>
    </footer>
   </div>
  </div>
  <script src="../assets/js/jquery-3.3.1.min.js">
  </script>
  <script src="../assets/js/plyr.polyfilled.min.js">
  </script>
  <script src="../assets/js/bootstrap.min.js">
  </script>
  <script src="../assets/js/jquery.mCustomScrollbar.concat.min.js">
  </script>
  <script src="../assets/js/katex.min.js">
  </script>
  <script>
   // Initialize Plyr video players
    const players = Array.from(document.querySelectorAll('video')).map(p => new Plyr(p));

    // render math equations
    let elMath = document.getElementsByClassName('mathquill');
    for (let i = 0, len = elMath.length; i < len; i += 1) {
      const el = elMath[i];

      katex.render(el.textContent, el, {
        throwOnError: false
      });
    }

    // this hack will make sure Bootstrap tabs work when using Handlebars
    if ($('#question-tabs').length && $('#user-answer-tabs').length) {
      $("#question-tabs a.nav-link").on('click', function () {
        $("#question-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
      $("#user-answer-tabs a.nav-link").on('click', function () {
        $("#user-answer-tab-contents .tab-pane").hide();
        $($(this).attr("href")).show();
      });
    } else {
      $("a.nav-link").on('click', function () {
        $(".tab-pane").hide();
        $($(this).attr("href")).show();
      });
    }

    // side bar events
    $(document).ready(function () {
      $("#sidebar").mCustomScrollbar({
        theme: "minimal"
      });

      $('#sidebarCollapse').on('click', function () {
        $('#sidebar, #content').toggleClass('active');
        $('.collapse.in').toggleClass('in');
        $('a[aria-expanded=true]').attr('aria-expanded', 'false');
      });

      // scroll to first video on page loading
      if ($('video').length) {
        $('html,body').animate({ scrollTop: $('div.plyr').prev().offset().top});
      }

      // auto play first video: this may not work with chrome/safari due to autoplay policy
      if (players && players.length > 0) {
        players[0].play();
      }

      // scroll sidebar to current concept
      const currentInSideBar = $( "ul.sidebar-list.components li a:contains('28. Color Classify')" )
      currentInSideBar.css( "text-decoration", "underline" );
      $("#sidebar").mCustomScrollbar('scrollTo', currentInSideBar);
    });
  </script>
 </body>
</html>
