WEBVTT
Kind: captions
Language: zh-CN

00:00:00.420 --> 00:00:04.599
训练阶段大致包括 从训练集中提取每个样本的特征

00:00:04.599 --> 00:00:08.529
并将这些特征向量

00:00:08.529 --> 00:00:13.189
与对应的标签一起提供给训练算法

00:00:13.189 --> 00:00:16.179
训练算法初始化一个模型

00:00:16.179 --> 00:00:20.230
然后使用特征向量和标签调整模型的参数

00:00:20.230 --> 00:00:24.530
通常这一步会涉及迭代过程

00:00:24.530 --> 00:00:28.950
迭代时 每次向分类器提供一个或多个样本 分类器预测其标签

00:00:28.949 --> 00:00:31.515
这些预测标签与真值之间的误差

00:00:31.515 --> 00:00:35.590
被用作修改模型参数的依据

00:00:35.590 --> 00:00:39.900
当这一误差低于某个阈值时 或迭代次数已达上限

00:00:39.899 --> 00:00:44.739
可以认为该模型已经经过了充分训练

00:00:44.740 --> 00:00:49.210
现在你可以使用测试集

00:00:49.210 --> 00:00:50.939
来验证该模型在新数据上的表现

00:00:50.939 --> 00:00:55.039
测试集上的误差通常要比在训练集上的大

00:00:55.039 --> 00:00:56.409
这在意料之中

00:00:56.409 --> 00:01:01.579
这两种误差通常都会随着对模型的进一步训练而降低

00:01:01.579 --> 00:01:04.310
然而 你必须小心一点

00:01:04.310 --> 00:01:08.090
如果一直训练模型 在超过某个临界点后

00:01:08.090 --> 00:01:12.890
训练误差可能会继续降低 而测试误差反而开始上升

00:01:12.890 --> 00:01:14.780
这种情况称为过拟合

00:01:14.780 --> 00:01:17.710
你的模型会很好地拟合训练数据

00:01:17.709 --> 00:01:21.099
但是却无法对新数据进行泛化

00:01:21.099 --> 00:01:25.689
还有一点 就是分类器的选择

00:01:25.689 --> 00:01:28.980
需要进行一些实验 才能知道

00:01:28.980 --> 00:01:31.900
哪种分类器对于给定的问题更有效

00:01:31.900 --> 00:01:35.621
本例中 我们将从支持向量机开始

00:01:35.621 --> 00:01:38.314
此前已证明 支持向量机对 HoG 特征很有效

00:01:38.314 --> 00:01:42.051
不过你可以自由选择你最终使用的分类器

00:01:42.052 --> 00:01:45.830
甚至可以综合使用多种分类器

