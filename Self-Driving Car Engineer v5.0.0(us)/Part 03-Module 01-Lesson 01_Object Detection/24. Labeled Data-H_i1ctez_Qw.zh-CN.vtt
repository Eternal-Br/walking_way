WEBVTT
Kind: captions
Language: zh-CN

00:00:00.340 --> 00:00:03.509
训练任何分类器都需要有标签数据

00:00:03.509 --> 00:00:04.979
而且是大量的有标签数据

00:00:04.980 --> 00:00:05.740
本例中

00:00:05.740 --> 00:00:10.800
你想要区分的两个类别是图像中的汽车和非汽车物体

00:00:10.800 --> 00:00:13.070
因此你同时需要这两种类别的数据

00:00:13.070 --> 00:00:15.830
如果只有视频本身

00:00:15.830 --> 00:00:19.829
就需要裁剪出这些区域 并按比例调节为统一的图像大小

00:00:19.829 --> 00:00:22.369
理想情况下 你需要使用平衡的数据集

00:00:22.370 --> 00:00:26.450
其中汽车和非汽车图像的数量应大致相等

00:00:26.449 --> 00:00:29.669
否则 分类器有可能

00:00:29.670 --> 00:00:33.560
试图将所有对象都预测为数据量较大的类别

00:00:33.560 --> 00:00:37.067
有一些处理不平衡数据集的技巧

00:00:37.067 --> 00:00:41.337
例如 可从数据量较小的类别中复制一些样本 以平衡数量

00:00:41.337 --> 00:00:46.215
对于车辆分类 如果没有足够的非汽车图像

00:00:46.215 --> 00:00:48.629
可以简单地从视频中截取更多非汽车的物体

00:00:48.628 --> 00:00:51.100
一旦有了足够大的数据集时

00:00:51.100 --> 00:00:54.174
你需要将其分成两个子集

00:00:54.174 --> 00:00:56.854
训练集和测试集

00:00:56.854 --> 00:01:00.784
顾名思义 在训练分类器时

00:01:00.784 --> 00:01:02.884
你将只使用训练集中的图像

00:01:02.884 --> 00:01:07.144
然后使用测试集来检验分类器对于新样本的识别能力

00:01:07.144 --> 00:01:11.384
为了避免数据中任何可能的顺序影响 在将数据集划分为训练集和测试集时

00:01:11.385 --> 00:01:16.255
你需要随机抽样或者打乱数据集

00:01:16.254 --> 00:01:19.399
分别对于训练集和测试集而言

00:01:19.400 --> 00:01:23.390
也应该尽可能保证两个子集内汽车和非汽车图像数量的平衡

00:01:23.390 --> 00:01:26.519
这些预处理可能看起来工作量很大

00:01:26.519 --> 00:01:32.079
但是要记住 如果机器学习算法的输入的是垃圾 那么输出的一定也是垃圾

00:01:32.079 --> 00:01:34.329
因此 对于提供给算法的数据需要特别小心

